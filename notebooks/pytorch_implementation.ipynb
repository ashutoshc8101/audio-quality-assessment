{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVAa1tdOE-5-",
        "outputId": "11440f54-2b15-430a-f6b3-93ddc01a1917"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
            "You should consider upgrading via the '/home/ashutosh/Desktop/ugmqa_project/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q librosa matplotlib spafe torch pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pknZQa7wt4L3"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import random_split, Dataset, DataLoader\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QqdzhPSpFJ5z"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "import IPython.display as ipd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from collections import defaultdict\n",
        "from spafe.utils import vis\n",
        "from spafe.features.lfcc import lfcc\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nHXfPJFBGX63"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, embed_size, num_heads):\n",
        "\n",
        "        super(SelfAttention, self).__init__()\n",
        "\n",
        "        self.embed_size = embed_size\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = embed_size // num_heads\n",
        "\n",
        "        assert (self.head_dim * num_heads ==\n",
        "                embed_size), \"Embed size needs to be divisible by heads\"\n",
        "\n",
        "        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
        "        self.keys = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
        "        self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
        "        self.fc_out = nn.Linear(num_heads * self.head_dim, embed_size)\n",
        "\n",
        "    def forward(self, value, key, query, mask):\n",
        "\n",
        "        N = query.shape[0]\n",
        "        value_len, key_len, query_len = value.shape[1], key.shape[1], query.shape[1]\n",
        "\n",
        "        # Split embedding into self.num_heads pieces\n",
        "        value = value.reshape(N, value_len, self.num_heads, self.head_dim)\n",
        "        key = key.reshape(N, key_len, self.num_heads, self.head_dim)\n",
        "        query = query.reshape(N, query_len, self.num_heads, self.head_dim)\n",
        "\n",
        "        values = self.values(value)\n",
        "        keys = self.keys(key)\n",
        "        queries = self.queries(query)\n",
        "        energy = torch.einsum(\n",
        "            \"nqhd,nkhd->nhqk\", [queries, keys])  # MatMul Q and K\n",
        "        # queries shape: (N, query_len, heads, heads_dim)\n",
        "        # keys shape: (N, query_len, heads, heads_dim)\n",
        "        # energy shape: (N, heads, query_len, key_len)\n",
        "        # print(\"Mask\", mask.shape)\n",
        "        # print(\"Energy\", energy.shape)\n",
        "\n",
        "        # energy = torch.zeros((N, self.num_heads, query_len, key_len)).to(device)\n",
        "\n",
        "        # mask = torch.zeros((1, 1, 1, key_len)).to(device)\n",
        "\n",
        "        if mask is not None:\n",
        "            # print(mask)\n",
        "            energy = energy.masked_fill(mask == 0, float(\"-1e20\"))\n",
        "            # print(energy[0][0][0])\n",
        "\n",
        "        attention = torch.softmax(energy / (self.embed_size ** 0.5), dim=3)\n",
        "\n",
        "        out = torch.einsum(\"nhql,nlhd->nqhd\", [attention, values])\n",
        "        # print(\"output_out:\", out.shape)\n",
        "        # print('Out shape', out.shape)\n",
        "        out = out.reshape(\n",
        "            N, query_len, self.num_heads * self.head_dim\n",
        "        )\n",
        "\n",
        "        out = self.fc_out(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uBb-2No1IHlL"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "  def __init__(self, embed_size, dropout, max_len = 5000):\n",
        "    super().__init__()\n",
        "\n",
        "    self.dropout = nn.Dropout(p = dropout)\n",
        "\n",
        "    position = torch.arange(max_len).unsqueeze(1)\n",
        "    div_term = torch.exp(torch.arange(0, embed_size, 2) * (-math.log(10000.0) / embed_size))\n",
        "    self.position_encoding = torch.zeros(max_len, embed_size).to(device)\n",
        "    self.position_encoding[:, 0::2] = torch.sin(position * div_term).to(device)\n",
        "    self.position_encoding[:, 1::2] = torch.cos(position * div_term).to(device)\n",
        "    self.register_buffer('pe', self.position_encoding)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # print('pe_x', x.shape)\n",
        "    # print('pe', self.position_encoding.shape)\n",
        "    x = x + self.position_encoding[:x.size(0)]\n",
        "    return self.dropout(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "m6FIvPEgIJib"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, embed_size, heads, dropout, forward_expansion):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "\n",
        "        self.attention = SelfAttention(embed_size, heads)\n",
        "        self.norm1 = nn.LayerNorm(embed_size)\n",
        "        self.norm2 = nn.LayerNorm(embed_size)\n",
        "\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(embed_size, forward_expansion * embed_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(forward_expansion * embed_size, embed_size)\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, value, key, query, mask):\n",
        "        attention = self.attention(value, key, query, mask)\n",
        "\n",
        "        x = self.dropout(self.norm1((attention + query)))\n",
        "\n",
        "        forward = self.feed_forward(x)\n",
        "        out = self.dropout(self.norm2(x + forward))\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mVmNcXqTILWw"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "  def __init__(\n",
        "    self,\n",
        "    src_vocab_size,\n",
        "    embed_size,\n",
        "    num_layers,\n",
        "    heads,\n",
        "    device,\n",
        "    forward_expansion,\n",
        "    dropout,\n",
        "    max_length\n",
        "  ):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.embed_size = embed_size\n",
        "    self.device = device\n",
        "    # self.position_embedding = PositionalEncoding(embed_size, dropout, src_vocab_size)\n",
        "    self.position_embedding = nn.Embedding(src_vocab_size, embed_size)\n",
        "\n",
        "    self.layers = nn.ModuleList(\n",
        "      [\n",
        "        TransformerBlock(embed_size, heads, dropout, forward_expansion) for _ in range(num_layers)\n",
        "      ]\n",
        "    )\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "  def forward(self, x, mask):\n",
        "    N, seq_length = x.shape\n",
        "    # print(N, seq_length)\n",
        "\n",
        "    positions = torch.arange(0, seq_length).expand(N, seq_length).to(self.device)\n",
        "    # print('positions shape', positions.shape)\n",
        "    out = self.dropout(self.position_embedding(positions))\n",
        "\n",
        "    for layer in self.layers:\n",
        "      out = layer(out, out, out, mask)\n",
        "\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4-NbKpF1ITI-"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "\n",
        "  def __init__(\n",
        "    self,\n",
        "    src_vocab_size,\n",
        "    src_pad_index,\n",
        "    embed_size = 256,\n",
        "    num_layers = 6,\n",
        "    forward_expansion = 4,\n",
        "    heads = 8,\n",
        "    dropout = 0,\n",
        "    device = \"cuda\",\n",
        "    max_length = 100\n",
        "  ):\n",
        "    super(Transformer, self).__init__()\n",
        "\n",
        "    self.encoder = Encoder(\n",
        "      src_vocab_size, embed_size, num_layers, heads,\n",
        "      device, forward_expansion, dropout, max_length)\n",
        "\n",
        "    self.src_pad_index = src_pad_index\n",
        "    self.output = nn.Linear(src_vocab_size * embed_size, 1)\n",
        "    self.device = device\n",
        "    self.embed_size = embed_size\n",
        "    self.src_vocab_size = src_vocab_size\n",
        "\n",
        "\n",
        "  def make_src_mask(self, src):\n",
        "    src_mask = (src != self.src_pad_index).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "    # (N, 1, 1, src_len)\n",
        "    return src_mask.to(self.device)\n",
        "\n",
        "\n",
        "  def forward(self, src):\n",
        "    src_mask = self.make_src_mask(src)\n",
        "    out = self.encoder(src, src_mask)\n",
        "\n",
        "    out = out.reshape(-1, self.src_vocab_size * self.embed_size)\n",
        "\n",
        "    return self.output(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "soinXdqjMxj5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "\n",
        "class AudioFeatureDataset(Dataset):\n",
        "    def __init__(self, annotations_file, mode='train'):\n",
        "        self.data = pd.read_csv(annotations_file)\n",
        "        self.data = self.data.drop(['Unnamed: 0'], axis=1)\n",
        "\n",
        "        # Splitting the dataset into train and validation sets\n",
        "        total_samples = len(self.data)\n",
        "        train_size = int(0.8 * total_samples)\n",
        "        valid_size = total_samples - train_size\n",
        "\n",
        "        if mode == 'train':\n",
        "            self.data = self.data.iloc[:train_size]\n",
        "        else:\n",
        "            self.data = self.data.iloc[train_size:]\n",
        "\n",
        "        self.features = torch.Tensor(self.data.drop(['class'], axis=1).values)\n",
        "        self.labels = torch.Tensor(self.data['class'].values)\n",
        "        self.mode = mode\n",
        "\n",
        "    def __len__(self):\n",
        "        # print(self.features.shape)\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.labels[idx]\n",
        "\n",
        "\n",
        "# Example usage\n",
        "dataset = AudioFeatureDataset('./extracted_audio_features.csv', mode='train')\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "# for batch in dataloader:\n",
        "#     x, y = batch\n",
        "#     # Your training code here\n",
        "# x_train = dataset[0][0]\n",
        "# x_target = dataset[0][1]\n",
        "\n",
        "# print(len(dataset))\n",
        "# print(len(dataset[0][0]))\n",
        "\n",
        "dataset_val = AudioFeatureDataset('./extracted_audio_features.csv', mode=\"val\")\n",
        "dataloader_val = DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "# print(len(dataset_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JKBauT7rV9dJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "eL44nAxMPBBV",
        "outputId": "2c6fa457-7d18-468d-d2ff-f3bb5ae04d8c"
      },
      "outputs": [],
      "source": [
        "num_layers = 1\n",
        "src_vocab_size = 297  # TIME-STEPS\n",
        "src_pad_index = 0\n",
        "embed_size = 256 #D-Model\n",
        "num_heads = 1\n",
        "dropout = 0.1\n",
        "output_size = 1\n",
        "forward_expansion = 4\n",
        "\n",
        "model = Transformer(\n",
        "  src_vocab_size,\n",
        "  src_pad_index,\n",
        "  embed_size = embed_size,\n",
        "  dropout = dropout,\n",
        "  heads = num_heads,\n",
        "  num_layers = num_layers,\n",
        "  forward_expansion = forward_expansion\n",
        "  ).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4, 297])\n",
            "tensor([0.4180, 0.9364, 0.2321, 0.4180], device='cuda:0',\n",
            "       grad_fn=<SqueezeBackward0>)\n"
          ]
        }
      ],
      "source": [
        "X = torch.Tensor([[0,124.46949,-21.54154,0,16.483715,36.6015,0,-25.834284,0,10.178377,0,-7.345142,10.264649,16.472473,7.895236,5.5313177,6.2877584,-4.182223,-14.012452,-7.7094264,0.4547759,-5.8861904,-13.388045,-6.9823565,1.1916866,-1.7707733,-5.276302,-0.35934502,1.7799568,-4.779073,-6.8897967,0.79337484,4.2686896,-2.5059521,-6.496715,-1.0943556,3.1531215,0.25546533,-2.272549,-0.73324627,0.0020391261,0.012858815,0.062261246,0.030906683,0.033696823,0.06754137,0.054984007,0.36406443,0.18963988,0.10330482,0.12989527,0.42003468,0.48301712,0.11749379,0.06369407,0.12233541,0.2568086,0.5382474,1.106481,1.4184383,0.71715385,0.35170192,0.09534879,0.0366585,0.102917545,0.087631606,0.03625296,0.06454905,0.095770694,0.12915519,0.25286278,0.2482152,0.20051777,0.39578456,0.28170255,0.3759659,0.4401238,0.90044194,0.8636782,1.1747689,0.7714911,0.818637,0.37247756,0.3380456,0.7661559,2.4523528,2.7824976,8.302962,16.734638,8.80889,12.927655,13.964713,7.212821,7.622612,17.17792,10.23075,8.3349285,5.6397433,3.6112895,0.6386233,0.24162434,0.34277353,0.36261582,0.3141538,0.38225174,0.47966504,0.03040914,0.0012386683,9.3100425e-05,7.8610115e-05,7.8027195e-05,5.490173e-06,1.6225702e-05,5.6767494e-06,4.4215603e-06,9.099585e-06,1.2576394e-06,2.412565e-06,7.926269e-07,2.0946077e-06,1.3263315e-06,6.3015705e-07,4.1206027e-07,7.42592e-07,5.666581e-07,2.967201e-07,1.7622109e-07,4.3961313e-07,1.7293216e-07,1.4194566e-07,1.8899503e-07,1.5307475e-07,9.427612e-08,1.06292724e-07,1.01943236e-07,6.155833e-08,7.990511e-08,6.0735445e-08,4.232562e-08,6.248923e-08,3.7052516e-08,4.0408686e-08,3.633701e-08,2.8342097e-08,3.3516038e-08,2.3205962e-08,2.8330943e-08,2.0632546e-08,2.3197451e-08,1.7732157e-08,1.965794e-08,1.6046194e-08,1.7022142e-08,1.4855194e-08,1.4529622e-08,1.42051055e-08,1.3379163e-08,1.3088586e-08,1.2451093e-08,1.209253e-08,1.2065797e-08,1.1807311e-08,1.1646068e-08,1.16453025e-08,1.1936379e-08,1.2163221e-08,1.1026455e-08,7.149512e-09,0.36461177,0.34337756,0.27882302,0.48984087,0.58728004,0.33111906,0.35057455,0.40294,0.37982342,0.38546938,0.35827973,0.3449619,4098.515885613107,4394.679597751644,2173.6066930992697,660.1920797101604,666.3801569895414,679.7044596914801,646.1064276646537,678.6052827762849,636.4525179151398,588.8034579300204,588.6927126149499,605.9566149564441,554.6815422905305,643.55633138673,635.2709118421336,593.1425591116601,689.9515513706316,753.8378337006548,713.6116050230352,665.575526379199,639.8702521661144,566.4381100383742,602.769675543065,636.9758223614031,838.8391505866864,1478.874805344335,1459.149044006308,1387.6915345139455,1353.654060604915,1380.012526068448,1383.4946564371012,1341.579689123074,1427.5678622884227,1397.7808753654772,1344.037783237732,1257.285128280657,1297.332690017431,1316.4388778935704,1307.883347941082,1283.9768778672214,1273.1843530634096,1278.0824064357296,1321.431115766408,1354.4814820287468,1333.5878041563171,1357.2018216795293,1347.5298328353635,1317.862385602503,1316.7824410928667,1363.7911817467896,1421.45053482153,1473.7295655749122,1513.3380612007554,1527.07320879706,1520.3705478366887,1481.8238543145394,1500.151441619609,1508.9669344602714,1481.524474097877,1445.1450034130887,1417.4826755078072,1453.824676109189,1476.554974221759,1457.7835067613787,1442.5007903703054,1446.138078746579,1480.3479277869212,1474.320222966424,1423.3878323139418,1360.8577255891676,1337.3912372750488,1400.7434254248976,1406.7530196210892,1371.0172331395806,1360.0256467642882,1360.1123709007084,1359.7692618475817,1349.6076963128105,1345.1738370383607,1343.4491732619308,1328.2974945469014,1314.617505626696,1321.0909928662404,1335.4841595848136,1343.4321393541222,1344.775088467436,1333.9444077975136,1305.7116252799508,1309.2780904215947,1308.5759110007473,1306.0999714339998,1355.6284484769956,1452.5165920413374,1475.6366023948713,1447.970350106245,1406.542142884293,1377.6039021203871,1278.4930177581896,1189.0178172699625,1205.2225452548764,1179.4867044106006,881.8538957920834,1197.5584167943596,1324.3785722370592,1361.4066076471468,1263.928152316742,1005.8203163981548,759.0834395666938,679.2875862507892,708.2743155303299,712.1759249973968,604.9816438504809,659.412993337054,789.7184528406086,815.1398626985261,915.8414552062778,773.3202934324213],\n",
        "                  [-397.86472,124.46949,0,-48.849564,16.483715,36.6015,-6.4991527,-25.834284,-1.2522386,10.178377,-5.218914,-7.345142,10.264649,16.472473,7.895236,5.5313177,6.2877584,-4.182223,-14.012452,-7.7094264,0.4547759,-5.8861904,-13.388045,-6.9823565,1.1916866,-1.7707733,-5.276302,-0.35934502,1.7799568,-4.779073,-6.8897967,0.79337484,4.2686896,-2.5059521,-6.496715,-1.0943556,3.1531215,0.25546533,-2.272549,-0.73324627,0.0020391261,0.012858815,0.062261246,0.030906683,0.033696823,0.06754137,0.054984007,0.36406443,0.18963988,0.10330482,0.12989527,0.42003468,0.48301712,0.11749379,0.06369407,0.12233541,0.2568086,0.5382474,1.106481,1.4184383,0.71715385,0.35170192,0.09534879,0.0366585,0.102917545,0.087631606,0.03625296,0.06454905,0.095770694,0.12915519,0.25286278,0.2482152,0.20051777,0.39578456,0.28170255,0.3759659,0.4401238,0.90044194,0.8636782,1.1747689,0.7714911,0.818637,0.37247756,0.3380456,0.7661559,2.4523528,2.7824976,8.302962,16.734638,8.80889,12.927655,13.964713,7.212821,7.622612,17.17792,10.23075,8.3349285,5.6397433,3.6112895,0.6386233,0.24162434,0.34277353,0.36261582,0.3141538,0.38225174,0.47966504,0.03040914,0.0012386683,9.3100425e-05,7.8610115e-05,7.8027195e-05,5.490173e-06,1.6225702e-05,5.6767494e-06,4.4215603e-06,9.099585e-06,1.2576394e-06,2.412565e-06,7.926269e-07,2.0946077e-06,1.3263315e-06,6.3015705e-07,4.1206027e-07,7.42592e-07,5.666581e-07,2.967201e-07,1.7622109e-07,4.3961313e-07,1.7293216e-07,1.4194566e-07,1.8899503e-07,1.5307475e-07,9.427612e-08,1.06292724e-07,1.01943236e-07,6.155833e-08,7.990511e-08,6.0735445e-08,4.232562e-08,6.248923e-08,3.7052516e-08,4.0408686e-08,3.633701e-08,2.8342097e-08,3.3516038e-08,2.3205962e-08,2.8330943e-08,2.0632546e-08,2.3197451e-08,1.7732157e-08,1.965794e-08,1.6046194e-08,1.7022142e-08,1.4855194e-08,1.4529622e-08,1.42051055e-08,1.3379163e-08,1.3088586e-08,1.2451093e-08,1.209253e-08,1.2065797e-08,1.1807311e-08,1.1646068e-08,1.16453025e-08,1.1936379e-08,1.2163221e-08,1.1026455e-08,7.149512e-09,0.36461177,0.34337756,0.27882302,0.48984087,0.58728004,0.33111906,0.35057455,0.40294,0.37982342,0.38546938,0.35827973,0.3449619,4098.515885613107,4394.679597751644,2173.6066930992697,660.1920797101604,666.3801569895414,679.7044596914801,646.1064276646537,678.6052827762849,636.4525179151398,588.8034579300204,588.6927126149499,605.9566149564441,554.6815422905305,643.55633138673,635.2709118421336,593.1425591116601,689.9515513706316,753.8378337006548,713.6116050230352,665.575526379199,639.8702521661144,566.4381100383742,602.769675543065,636.9758223614031,838.8391505866864,1478.874805344335,1459.149044006308,1387.6915345139455,1353.654060604915,1380.012526068448,1383.4946564371012,1341.579689123074,1427.5678622884227,1397.7808753654772,1344.037783237732,1257.285128280657,1297.332690017431,1316.4388778935704,1307.883347941082,1283.9768778672214,1273.1843530634096,1278.0824064357296,1321.431115766408,1354.4814820287468,1333.5878041563171,1357.2018216795293,1347.5298328353635,1317.862385602503,1316.7824410928667,1363.7911817467896,1421.45053482153,1473.7295655749122,1513.3380612007554,1527.07320879706,1520.3705478366887,1481.8238543145394,1500.151441619609,1508.9669344602714,1481.524474097877,1445.1450034130887,1417.4826755078072,1453.824676109189,1476.554974221759,1457.7835067613787,1442.5007903703054,1446.138078746579,1480.3479277869212,1474.320222966424,1423.3878323139418,1360.8577255891676,1337.3912372750488,1400.7434254248976,1406.7530196210892,1371.0172331395806,1360.0256467642882,1360.1123709007084,1359.7692618475817,1349.6076963128105,1345.1738370383607,1343.4491732619308,1328.2974945469014,1314.617505626696,1321.0909928662404,1335.4841595848136,1343.4321393541222,1344.775088467436,1333.9444077975136,1305.7116252799508,1309.2780904215947,1308.5759110007473,1306.0999714339998,1355.6284484769956,1452.5165920413374,1475.6366023948713,1447.970350106245,1406.542142884293,1377.6039021203871,1278.4930177581896,1189.0178172699625,1205.2225452548764,1179.4867044106006,881.8538957920834,1197.5584167943596,1324.3785722370592,1361.4066076471468,1263.928152316742,1005.8203163981548,759.0834395666938,679.2875862507892,708.2743155303299,712.1759249973968,604.9816438504809,659.412993337054,789.7184528406086,815.1398626985261,915.8414552062778,773.3202934324213],\n",
        "                  [-397.86472,0,-21.54154,-48.849564,16.483715,36.6015,-6.4991527,-25.834284,-1.2522386,10.178377,-5.218914,-7.345142,10.264649,16.472473,7.895236,5.5313177,6.2877584,-4.182223,-14.012452,-7.7094264,0.4547759,-5.8861904,-13.388045,-6.9823565,1.1916866,-1.7707733,-5.276302,-0.35934502,1.7799568,-4.779073,-6.8897967,0.79337484,4.2686896,-2.5059521,-6.496715,-1.0943556,3.1531215,0.25546533,-2.272549,-0.73324627,0.0020391261,0.012858815,0.062261246,0.030906683,0.033696823,0.06754137,0.054984007,0.36406443,0.18963988,0.10330482,0.12989527,0.42003468,0.48301712,0.11749379,0.06369407,0.12233541,0.2568086,0.5382474,1.106481,1.4184383,0.71715385,0.35170192,0.09534879,0.0366585,0.102917545,0.087631606,0.03625296,0.06454905,0.095770694,0.12915519,0.25286278,0.2482152,0.20051777,0.39578456,0.28170255,0.3759659,0.4401238,0.90044194,0.8636782,1.1747689,0.7714911,0.818637,0.37247756,0.3380456,0.7661559,2.4523528,2.7824976,8.302962,16.734638,8.80889,12.927655,13.964713,7.212821,7.622612,17.17792,10.23075,8.3349285,5.6397433,3.6112895,0.6386233,0.24162434,0.34277353,0.36261582,0.3141538,0.38225174,0.47966504,0.03040914,0.0012386683,9.3100425e-05,7.8610115e-05,7.8027195e-05,5.490173e-06,1.6225702e-05,5.6767494e-06,4.4215603e-06,9.099585e-06,1.2576394e-06,2.412565e-06,7.926269e-07,2.0946077e-06,1.3263315e-06,6.3015705e-07,4.1206027e-07,7.42592e-07,5.666581e-07,2.967201e-07,1.7622109e-07,4.3961313e-07,1.7293216e-07,1.4194566e-07,1.8899503e-07,1.5307475e-07,9.427612e-08,1.06292724e-07,1.01943236e-07,6.155833e-08,7.990511e-08,6.0735445e-08,4.232562e-08,6.248923e-08,3.7052516e-08,4.0408686e-08,3.633701e-08,2.8342097e-08,3.3516038e-08,2.3205962e-08,2.8330943e-08,2.0632546e-08,2.3197451e-08,1.7732157e-08,1.965794e-08,1.6046194e-08,1.7022142e-08,1.4855194e-08,1.4529622e-08,1.42051055e-08,1.3379163e-08,1.3088586e-08,1.2451093e-08,1.209253e-08,1.2065797e-08,1.1807311e-08,1.1646068e-08,1.16453025e-08,1.1936379e-08,1.2163221e-08,1.1026455e-08,7.149512e-09,0.36461177,0.34337756,0.27882302,0.48984087,0.58728004,0.33111906,0.35057455,0.40294,0.37982342,0.38546938,0.35827973,0.3449619,4098.515885613107,4394.679597751644,2173.6066930992697,660.1920797101604,666.3801569895414,679.7044596914801,646.1064276646537,678.6052827762849,636.4525179151398,588.8034579300204,588.6927126149499,605.9566149564441,554.6815422905305,643.55633138673,635.2709118421336,593.1425591116601,689.9515513706316,753.8378337006548,713.6116050230352,665.575526379199,639.8702521661144,566.4381100383742,602.769675543065,636.9758223614031,838.8391505866864,1478.874805344335,1459.149044006308,1387.6915345139455,1353.654060604915,1380.012526068448,1383.4946564371012,1341.579689123074,1427.5678622884227,1397.7808753654772,1344.037783237732,1257.285128280657,1297.332690017431,1316.4388778935704,1307.883347941082,1283.9768778672214,1273.1843530634096,1278.0824064357296,1321.431115766408,1354.4814820287468,1333.5878041563171,1357.2018216795293,1347.5298328353635,1317.862385602503,1316.7824410928667,1363.7911817467896,1421.45053482153,1473.7295655749122,1513.3380612007554,1527.07320879706,1520.3705478366887,1481.8238543145394,1500.151441619609,1508.9669344602714,1481.524474097877,1445.1450034130887,1417.4826755078072,1453.824676109189,1476.554974221759,1457.7835067613787,1442.5007903703054,1446.138078746579,1480.3479277869212,1474.320222966424,1423.3878323139418,1360.8577255891676,1337.3912372750488,1400.7434254248976,1406.7530196210892,1371.0172331395806,1360.0256467642882,1360.1123709007084,1359.7692618475817,1349.6076963128105,1345.1738370383607,1343.4491732619308,1328.2974945469014,1314.617505626696,1321.0909928662404,1335.4841595848136,1343.4321393541222,1344.775088467436,1333.9444077975136,1305.7116252799508,1309.2780904215947,1308.5759110007473,1306.0999714339998,1355.6284484769956,1452.5165920413374,1475.6366023948713,1447.970350106245,1406.542142884293,1377.6039021203871,1278.4930177581896,1189.0178172699625,1205.2225452548764,1179.4867044106006,881.8538957920834,1197.5584167943596,1324.3785722370592,1361.4066076471468,1263.928152316742,1005.8203163981548,759.0834395666938,679.2875862507892,708.2743155303299,712.1759249973968,604.9816438504809,659.412993337054,789.7184528406086,815.1398626985261,915.8414552062778,773.3202934324213],\n",
        "                  [0,124.46949,-21.54154,-48.849564,16.483715,36.6015,-6.4991527,-25.834284,-1.2522386,10.178377,-5.218914,-7.345142,10.264649,16.472473,7.895236,5.5313177,6.2877584,-4.182223,-14.012452,-7.7094264,0.4547759,-5.8861904,-13.388045,-6.9823565,1.1916866,-1.7707733,-5.276302,-0.35934502,1.7799568,-4.779073,-6.8897967,0.79337484,4.2686896,-2.5059521,-6.496715,-1.0943556,3.1531215,0.25546533,-2.272549,-0.73324627,0.0020391261,0.012858815,0.062261246,0.030906683,0.033696823,0.06754137,0.054984007,0.36406443,0.18963988,0.10330482,0.12989527,0.42003468,0.48301712,0.11749379,0.06369407,0.12233541,0.2568086,0.5382474,1.106481,1.4184383,0.71715385,0.35170192,0.09534879,0.0366585,0.102917545,0.087631606,0.03625296,0.06454905,0.095770694,0.12915519,0.25286278,0.2482152,0.20051777,0.39578456,0.28170255,0.3759659,0.4401238,0.90044194,0.8636782,1.1747689,0.7714911,0.818637,0.37247756,0.3380456,0.7661559,2.4523528,2.7824976,8.302962,16.734638,8.80889,12.927655,13.964713,7.212821,7.622612,17.17792,10.23075,8.3349285,5.6397433,3.6112895,0.6386233,0.24162434,0.34277353,0.36261582,0.3141538,0.38225174,0.47966504,0.03040914,0.0012386683,9.3100425e-05,7.8610115e-05,7.8027195e-05,5.490173e-06,1.6225702e-05,5.6767494e-06,4.4215603e-06,9.099585e-06,1.2576394e-06,2.412565e-06,7.926269e-07,2.0946077e-06,1.3263315e-06,6.3015705e-07,4.1206027e-07,7.42592e-07,5.666581e-07,2.967201e-07,1.7622109e-07,4.3961313e-07,1.7293216e-07,1.4194566e-07,1.8899503e-07,1.5307475e-07,9.427612e-08,1.06292724e-07,1.01943236e-07,6.155833e-08,7.990511e-08,6.0735445e-08,4.232562e-08,6.248923e-08,3.7052516e-08,4.0408686e-08,3.633701e-08,2.8342097e-08,3.3516038e-08,2.3205962e-08,2.8330943e-08,2.0632546e-08,2.3197451e-08,1.7732157e-08,1.965794e-08,1.6046194e-08,1.7022142e-08,1.4855194e-08,1.4529622e-08,1.42051055e-08,1.3379163e-08,1.3088586e-08,1.2451093e-08,1.209253e-08,1.2065797e-08,1.1807311e-08,1.1646068e-08,1.16453025e-08,1.1936379e-08,1.2163221e-08,1.1026455e-08,7.149512e-09,0.36461177,0.34337756,0.27882302,0.48984087,0.58728004,0.33111906,0.35057455,0.40294,0.37982342,0.38546938,0.35827973,0.3449619,4098.515885613107,4394.679597751644,2173.6066930992697,660.1920797101604,666.3801569895414,679.7044596914801,646.1064276646537,678.6052827762849,636.4525179151398,588.8034579300204,588.6927126149499,605.9566149564441,554.6815422905305,643.55633138673,635.2709118421336,593.1425591116601,689.9515513706316,753.8378337006548,713.6116050230352,665.575526379199,639.8702521661144,566.4381100383742,602.769675543065,636.9758223614031,838.8391505866864,1478.874805344335,1459.149044006308,1387.6915345139455,1353.654060604915,1380.012526068448,1383.4946564371012,1341.579689123074,1427.5678622884227,1397.7808753654772,1344.037783237732,1257.285128280657,1297.332690017431,1316.4388778935704,1307.883347941082,1283.9768778672214,1273.1843530634096,1278.0824064357296,1321.431115766408,1354.4814820287468,1333.5878041563171,1357.2018216795293,1347.5298328353635,1317.862385602503,1316.7824410928667,1363.7911817467896,1421.45053482153,1473.7295655749122,1513.3380612007554,1527.07320879706,1520.3705478366887,1481.8238543145394,1500.151441619609,1508.9669344602714,1481.524474097877,1445.1450034130887,1417.4826755078072,1453.824676109189,1476.554974221759,1457.7835067613787,1442.5007903703054,1446.138078746579,1480.3479277869212,1474.320222966424,1423.3878323139418,1360.8577255891676,1337.3912372750488,1400.7434254248976,1406.7530196210892,1371.0172331395806,1360.0256467642882,1360.1123709007084,1359.7692618475817,1349.6076963128105,1345.1738370383607,1343.4491732619308,1328.2974945469014,1314.617505626696,1321.0909928662404,1335.4841595848136,1343.4321393541222,1344.775088467436,1333.9444077975136,1305.7116252799508,1309.2780904215947,1308.5759110007473,1306.0999714339998,1355.6284484769956,1452.5165920413374,1475.6366023948713,1447.970350106245,1406.542142884293,1377.6039021203871,1278.4930177581896,1189.0178172699625,1205.2225452548764,1179.4867044106006,881.8538957920834,1197.5584167943596,1324.3785722370592,1361.4066076471468,1263.928152316742,1005.8203163981548,759.0834395666938,679.2875862507892,708.2743155303299,712.1759249973968,604.9816438504809,659.412993337054,789.7184528406086,815.1398626985261,915.8414552062778,773.3202934324213]])\n",
        "\n",
        "X = X.to(device)\n",
        "\n",
        "print(X.shape)\n",
        "# y = torch.Tensor([3.21]).to(device)\n",
        "\n",
        "pred = model(X).squeeze()\n",
        "print(pred)\n",
        "# loss_fn = nn.MSELoss()\n",
        "# print(loss_fn(pred, y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Ys2SVUuyQZou"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "batch 1 loss: 0.02701063632965088\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch 101 loss: 2.0417183506910805\n",
            "batch 201 loss: 2.0172501968889263\n",
            "batch 301 loss: 2.0605886064842345\n",
            "batch 401 loss: 1.837338819077704\n",
            "batch 501 loss: 1.589658853382885\n",
            "batch 601 loss: 2.0707690384100714\n",
            "batch 701 loss: 1.6053027277103684\n",
            "batch 801 loss: 1.7029430963570484\n",
            "batch 901 loss: 1.6696691812602331\n",
            "batch 1001 loss: 1.9671338822273539\n",
            "batch 1101 loss: 1.7813753490003001\n",
            "batch 1201 loss: 1.785812394211962\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/home/ashutosh/Desktop/ugmqa_project/notebooks/pytorch_implementation.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ashutosh/Desktop/ugmqa_project/notebooks/pytorch_implementation.ipynb#X15sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ashutosh/Desktop/ugmqa_project/notebooks/pytorch_implementation.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m-------------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ashutosh/Desktop/ugmqa_project/notebooks/pytorch_implementation.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mfor\u001b[39;00m batch, (X, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ashutosh/Desktop/ugmqa_project/notebooks/pytorch_implementation.ipynb#X15sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         \u001b[39m# Compute prediction and loss\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ashutosh/Desktop/ugmqa_project/notebooks/pytorch_implementation.ipynb#X15sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         \u001b[39m# print('X', X.shape)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ashutosh/Desktop/ugmqa_project/notebooks/pytorch_implementation.ipynb#X15sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         X \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ashutosh/Desktop/ugmqa_project/notebooks/pytorch_implementation.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(device)\n",
            "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
            "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    205\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[39m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[39m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[39mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[39m=\u001b[39;49mdefault_collate_fn_map)\n",
            "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
            "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
            "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mif\u001b[39;00m collate_fn_map \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     \u001b[39mif\u001b[39;00m elem_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 119\u001b[0m         \u001b[39mreturn\u001b[39;00m collate_fn_map[elem_type](batch, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map)\n\u001b[1;32m    121\u001b[0m     \u001b[39mfor\u001b[39;00m collate_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    122\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collate_type):\n",
            "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    160\u001b[0m     storage \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39m_typed_storage()\u001b[39m.\u001b[39m_new_shared(numel, device\u001b[39m=\u001b[39melem\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    161\u001b[0m     out \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mnew(storage)\u001b[39m.\u001b[39mresize_(\u001b[39mlen\u001b[39m(batch), \u001b[39m*\u001b[39m\u001b[39mlist\u001b[39m(elem\u001b[39m.\u001b[39msize()))\n\u001b[0;32m--> 162\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack(batch, \u001b[39m0\u001b[39;49m, out\u001b[39m=\u001b[39;49mout)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.000003)\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "running_loss = 0.\n",
        "last_loss = 0.\n",
        "\n",
        "model.train()\n",
        "\n",
        "epochs = 1000\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        # print('X', X.shape)\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(X)\n",
        "        # print(\"Prediction\")\n",
        "        pred = pred.squeeze()\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # losses.append(loss.to('cpu').detach().numpy())\n",
        "        # iterations += 1\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        # print(\"Loss gradient\", loss.grad)\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            last_loss = running_loss / 100  # loss per batch\n",
        "            print('batch {} loss: {}'.format(batch + 1, last_loss))\n",
        "            # tb_x = epoch * len(dataloader) + batch + 1\n",
        "            # tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
        "            running_loss = 0.\n",
        "\n",
        "    model.eval()\n",
        "    size = len(dataloader_val.dataset)\n",
        "    num_batches = len(dataloader_val)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for batch, (X, y) in enumerate(dataloader_val):\n",
        "          X = X.to(device)\n",
        "          y = y.to(device)\n",
        "          pred = model(X)\n",
        "          test_loss += loss_fn(pred, y).item()\n",
        "          correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    \n",
        "\n",
        "print('Done')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "Yn7xm6aGUvMP",
        "outputId": "9f0a1429-44ea-4384-b593-185a5575fb30"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'losses' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/home/ashutosh/Desktop/ugmqa_project/colab_model.ipynb Cell 14\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ashutosh/Desktop/ugmqa_project/colab_model.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# run\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ashutosh/Desktop/ugmqa_project/colab_model.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ashutosh/Desktop/ugmqa_project/colab_model.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(losses)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ashutosh/Desktop/ugmqa_project/colab_model.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m\"\u001b[39m\u001b[39mIterations\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ashutosh/Desktop/ugmqa_project/colab_model.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m plt\u001b[39m.\u001b[39mylabel(\u001b[39m\"\u001b[39m\u001b[39mLoss\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'losses' is not defined"
          ]
        }
      ],
      "source": [
        "# run\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "# plt.savefig(\"training.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHImI0fDU8mK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

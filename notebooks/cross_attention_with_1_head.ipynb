{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nXRPF7T0b-QZ",
    "outputId": "821fc7ca-79e6-4cf6-e81d-37fd685b71f3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/home/ashutosh/Desktop/ugmqa_project/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#run\n",
    "!pip install -q spafe pandas tensorflow seaborn opencv-python tqdm librosa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "s2K5aSHYb-Sm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#run\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import defaultdict\n",
    "from spafe.utils import vis\n",
    "from spafe.features.lfcc import lfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-xNIFhPtb-U5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-15 22:37:29.298584: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#run\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "QgbvNKYAb-YM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import ResNet50,ResNet101\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.model_selection import StratifiedKFold , KFold ,RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "LXsQV7ivcIcc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#run\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # add the mask zero out padding tokens.\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  return tf.matmul(attention_weights, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7WB2_09_e-qt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#run\n",
    "# This allows to the transformer to know where there is real data and where it is padded\n",
    "def create_padding_mask(seq):\n",
    "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "  # add extra dimensions to add the padding\n",
    "  # to the attention logits.\n",
    "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PjEQIR8TcIe3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#run\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # linear layers\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # split heads\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8hF4xYdLcSQA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#run\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "    # apply sin to even index in the array\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # apply cos to odd index in the array\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "j7ewC3iBcSSo",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#run\n",
    "def encoder_layer(units, d_model, num_heads, dropout,name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,d_model ), name=\"inputs\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "  print(padding_mask)\n",
    "\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention1\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "  attention1 = tf.keras.layers.Dropout(rate=dropout)(attention1)\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention1)\n",
    "    \n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention2\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention2)\n",
    "\n",
    "  attention3 = MultiHeadAttention(\n",
    "      d_model, 1, name=\"attention3\")({\n",
    "          'query': attention1,\n",
    "          'key': attention2,\n",
    "          'value': attention1,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "  attention3 = tf.keras.layers.Dropout(rate=dropout)(attention3)\n",
    "  attention3 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention3)\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention3)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention3 + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_8IFloblcSWJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#run\n",
    "def encoder(time_steps,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            projection,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,d_model), name=\"inputs\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  if projection=='linear':\n",
    "    ## We implement a linear projection based on Very Deep Self-Attention Networks for End-to-End Speech Recognition. Retrieved from https://arxiv.org/abs/1904.13377\n",
    "    projection=tf.keras.layers.Dense( d_model,use_bias=True, activation='linear')(inputs)\n",
    "    print('linear')\n",
    "\n",
    "  else:\n",
    "    projection=tf.identity(inputs)\n",
    "    print('none')\n",
    "\n",
    "  projection *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "  projection = PositionalEncoding(time_steps, d_model)(projection)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(projection)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "NXgJh2PpcIiK",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#run\n",
    "def transformer(time_steps,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                output_size,\n",
    "                projection,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,d_model), name=\"inputs\")\n",
    "\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(tf.dtypes.cast(\n",
    "\n",
    "      #Like our input has a dimension of length X d_model but the masking is applied to a vector\n",
    "      # We get the sum for each row and result is a vector. So, if result is 0 it is because in that position was masked\n",
    "      tf.math.reduce_sum(\n",
    "      inputs,\n",
    "      axis=2,\n",
    "      keepdims=False,\n",
    "      name=None\n",
    "  ), tf.int32))\n",
    "\n",
    "  enc_outputs = encoder(\n",
    "      time_steps=time_steps,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "      projection=projection,\n",
    "      name='encoder'\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  #We reshape for feeding our FC in the next step\n",
    "  outputs=tf.reshape(enc_outputs,(-1,time_steps*d_model))\n",
    "\n",
    "  #We predict our class\n",
    "  outputs = tf.keras.layers.Dense(units=output_size,use_bias=True, name=\"outputs\")(outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs], outputs=outputs, name='audio_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "9H-kkyuLcbPZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#run\n",
    "# num_batch_size = 32\n",
    "# num_epochs = 500\n",
    "# N_SPLIT = 10\n",
    "# num_labels=5\n",
    "# num_classes=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u4Iw3KzecbRt",
    "outputId": "0ffe72e2-2c24-4cbd-9441-a681fcf507e4",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2075, 298)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ajit\n",
    "# df = pd.read_csv('/content/drive/MyDrive/DatabaseDistorted/final_tii_all_finaldata/features/2075_concatenate5_spectral2.csv')\n",
    "# dm\n",
    "# df = pd.read_csv('./DatabaseDistorted/final_tii_all_finaldata/features/2075_concatenate_dm.csv')\n",
    "df = pd.read_csv('./audio_features.csv')\n",
    "\n",
    "\n",
    "# df = pd.read_csv('/content/drive/MyDrive/DatabaseDistorted/final_tii_all_finaldata/features/melspectogram_mean_newdm_2075.csv')\n",
    "# df = pd.read_csv('/content/drive/MyDrive/DatabaseDistorted/final_tii_all_finaldata/features/chroma_cqt_simple_mean_newdm_2075.csv')\n",
    "# df = pd.read_csv('/content/drive/MyDrive/DatabaseDistorted/final_tii_all_finaldata/features/mfcc_simple_mean_newdm_2075.csv')\n",
    "# df = pd.read_csv('/content/drive/MyDrive/DatabaseDistorted/final_tii_all_finaldata/features/spectral_centroid_meandm_2075_200.csv')\n",
    "\n",
    "df = df.drop(['Unnamed: 0'], axis = 1)\n",
    "df = df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2HrbtbLXcbTx",
    "outputId": "7a1af2ba-848e-44d8-d239-a2518c22f9bd",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(415, 298)\n",
      "(415, 298)\n",
      "(415, 298)\n",
      "(415, 298)\n",
      "(415, 298)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "siz=415\n",
    "df_read = df.copy()\n",
    "df1 = df_read.sample(siz)\n",
    "df_read = df_read.drop(df1.index)\n",
    "df2 = df_read.sample(siz)\n",
    "df_read = df_read.drop(df2.index)\n",
    "df3 = df_read.sample(siz)\n",
    "df_read = df_read.drop(df3.index)\n",
    "df4 = df_read.sample(siz)\n",
    "df_read = df_read.drop(df4.index)\n",
    "df5 = df_read.copy()\n",
    "\n",
    "print(df1.shape)\n",
    "print(df2.shape)\n",
    "print(df3.shape)\n",
    "print(df4.shape)\n",
    "print(df5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_j19bgqpcbWT",
    "outputId": "e4e9f119-b436-44fe-ab74-572cf6d7bca3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([ 881,  453, 2004, 1353,  281,  941, 1185, 1159, 1138,  599,\n",
      "       ...\n",
      "        834, 1730,  353, 1345, 1190, 1375,  185,  701, 1671, 1982],\n",
      "      dtype='int64', length=415)\n"
     ]
    }
   ],
   "source": [
    "q = list(df1.index)+list(df2.index)+list(df3.index)+list(df4.index)+list(df5.index)\n",
    "print(df1.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>288</th>\n",
       "      <th>289</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>115.100464</td>\n",
       "      <td>116.435690</td>\n",
       "      <td>-33.895737</td>\n",
       "      <td>21.440712</td>\n",
       "      <td>-8.445481</td>\n",
       "      <td>-2.221351</td>\n",
       "      <td>-5.662595</td>\n",
       "      <td>-5.307188</td>\n",
       "      <td>-3.395119</td>\n",
       "      <td>1.959972</td>\n",
       "      <td>...</td>\n",
       "      <td>1924.734414</td>\n",
       "      <td>2214.323973</td>\n",
       "      <td>2369.313522</td>\n",
       "      <td>1993.016083</td>\n",
       "      <td>1656.398893</td>\n",
       "      <td>1712.388520</td>\n",
       "      <td>1877.955538</td>\n",
       "      <td>2202.385976</td>\n",
       "      <td>2197.057367</td>\n",
       "      <td>1.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>-81.505840</td>\n",
       "      <td>93.929110</td>\n",
       "      <td>2.407967</td>\n",
       "      <td>5.197178</td>\n",
       "      <td>-4.273181</td>\n",
       "      <td>15.114481</td>\n",
       "      <td>-12.457763</td>\n",
       "      <td>-2.422184</td>\n",
       "      <td>-10.028605</td>\n",
       "      <td>11.997586</td>\n",
       "      <td>...</td>\n",
       "      <td>2165.990403</td>\n",
       "      <td>2121.735482</td>\n",
       "      <td>2169.657425</td>\n",
       "      <td>2299.472756</td>\n",
       "      <td>2309.287640</td>\n",
       "      <td>2272.999651</td>\n",
       "      <td>2427.676392</td>\n",
       "      <td>2451.911800</td>\n",
       "      <td>2408.656902</td>\n",
       "      <td>1.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>-301.374900</td>\n",
       "      <td>286.829930</td>\n",
       "      <td>-56.174410</td>\n",
       "      <td>-25.532795</td>\n",
       "      <td>53.723870</td>\n",
       "      <td>-20.187690</td>\n",
       "      <td>-24.548950</td>\n",
       "      <td>25.045732</td>\n",
       "      <td>-8.054552</td>\n",
       "      <td>-20.254957</td>\n",
       "      <td>...</td>\n",
       "      <td>902.227666</td>\n",
       "      <td>895.068748</td>\n",
       "      <td>792.717657</td>\n",
       "      <td>816.468468</td>\n",
       "      <td>821.499510</td>\n",
       "      <td>797.085182</td>\n",
       "      <td>830.891295</td>\n",
       "      <td>837.543881</td>\n",
       "      <td>856.526688</td>\n",
       "      <td>1.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>-354.598450</td>\n",
       "      <td>259.105130</td>\n",
       "      <td>120.287290</td>\n",
       "      <td>-6.172213</td>\n",
       "      <td>-55.095108</td>\n",
       "      <td>-30.534496</td>\n",
       "      <td>13.320685</td>\n",
       "      <td>27.653042</td>\n",
       "      <td>7.574259</td>\n",
       "      <td>-16.686695</td>\n",
       "      <td>...</td>\n",
       "      <td>541.573084</td>\n",
       "      <td>527.706392</td>\n",
       "      <td>516.779659</td>\n",
       "      <td>516.765627</td>\n",
       "      <td>550.828158</td>\n",
       "      <td>547.339139</td>\n",
       "      <td>551.372349</td>\n",
       "      <td>539.345737</td>\n",
       "      <td>516.670265</td>\n",
       "      <td>1.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>13.566546</td>\n",
       "      <td>20.589693</td>\n",
       "      <td>16.374050</td>\n",
       "      <td>13.352259</td>\n",
       "      <td>7.065914</td>\n",
       "      <td>7.064869</td>\n",
       "      <td>3.771653</td>\n",
       "      <td>3.909107</td>\n",
       "      <td>1.383886</td>\n",
       "      <td>4.150478</td>\n",
       "      <td>...</td>\n",
       "      <td>4835.892625</td>\n",
       "      <td>4971.914880</td>\n",
       "      <td>5068.061026</td>\n",
       "      <td>4916.267485</td>\n",
       "      <td>4950.245484</td>\n",
       "      <td>5003.574506</td>\n",
       "      <td>4919.739213</td>\n",
       "      <td>4890.999577</td>\n",
       "      <td>5021.892732</td>\n",
       "      <td>1.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 298 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2          3          4          5  \\\n",
       "881   115.100464  116.435690  -33.895737  21.440712  -8.445481  -2.221351   \n",
       "453   -81.505840   93.929110    2.407967   5.197178  -4.273181  15.114481   \n",
       "2004 -301.374900  286.829930  -56.174410 -25.532795  53.723870 -20.187690   \n",
       "1353 -354.598450  259.105130  120.287290  -6.172213 -55.095108 -30.534496   \n",
       "281    13.566546   20.589693   16.374050  13.352259   7.065914   7.064869   \n",
       "\n",
       "              6          7          8          9  ...          288  \\\n",
       "881   -5.662595  -5.307188  -3.395119   1.959972  ...  1924.734414   \n",
       "453  -12.457763  -2.422184 -10.028605  11.997586  ...  2165.990403   \n",
       "2004 -24.548950  25.045732  -8.054552 -20.254957  ...   902.227666   \n",
       "1353  13.320685  27.653042   7.574259 -16.686695  ...   541.573084   \n",
       "281    3.771653   3.909107   1.383886   4.150478  ...  4835.892625   \n",
       "\n",
       "              289          290          291          292          293  \\\n",
       "881   2214.323973  2369.313522  1993.016083  1656.398893  1712.388520   \n",
       "453   2121.735482  2169.657425  2299.472756  2309.287640  2272.999651   \n",
       "2004   895.068748   792.717657   816.468468   821.499510   797.085182   \n",
       "1353   527.706392   516.779659   516.765627   550.828158   547.339139   \n",
       "281   4971.914880  5068.061026  4916.267485  4950.245484  5003.574506   \n",
       "\n",
       "              294          295          296  class  \n",
       "881   1877.955538  2202.385976  2197.057367   1.61  \n",
       "453   2427.676392  2451.911800  2408.656902   1.15  \n",
       "2004   830.891295   837.543881   856.526688   1.76  \n",
       "1353   551.372349   539.345737   516.670265   1.24  \n",
       "281   4919.739213  4890.999577  5021.892732   1.08  \n",
       "\n",
       "[5 rows x 298 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.concat([df1,df2,df3,df4], axis=0)\n",
    "train = train.dropna()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uT0Jrfa5cbZv",
    "outputId": "765d52d9-b8e2-4f6d-cd94-261bb7f7c39d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(1660, 1, 296)\n",
      "d_model 296\n",
      "num_heads 4\n",
      "TIME STEPS 1\n",
      "linear\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, None), dtype=tf.float32, name='padding_mask'), name='padding_mask', description=\"created by layer 'padding_mask'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, None), dtype=tf.float32, name='padding_mask'), name='padding_mask', description=\"created by layer 'padding_mask'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, None), dtype=tf.float32, name='padding_mask'), name='padding_mask', description=\"created by layer 'padding_mask'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, None), dtype=tf.float32, name='padding_mask'), name='padding_mask', description=\"created by layer 'padding_mask'\")\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ashutosh/Desktop/ugmqa_project/notebooks/cross_attention_with_1_head.ipynb Cell 17\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ashutosh/Desktop/ugmqa_project/notebooks/cross_attention_with_1_head.ipynb#X22sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(\u001b[39m0.000003\u001b[39m), loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ashutosh/Desktop/ugmqa_project/notebooks/cross_attention_with_1_head.ipynb#X22sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39m# model.compile(optimizer=tf.keras.optimizers.SGD(0.01), loss='mae')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ashutosh/Desktop/ugmqa_project/notebooks/cross_attention_with_1_head.ipynb#X22sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ashutosh/Desktop/ugmqa_project/notebooks/cross_attention_with_1_head.ipynb#X22sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m# callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience=80, restore_best_weights=True)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ashutosh/Desktop/ugmqa_project/notebooks/cross_attention_with_1_head.ipynb#X22sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39m# history = model.fit(X_train,Y_train, epochs=1000, validation_data=(X_val, Y_val), callbacks=[callback])\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ashutosh/Desktop/ugmqa_project/notebooks/cross_attention_with_1_head.ipynb#X22sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train,Y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_val, Y_val))\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:873\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[39m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   initializers \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 873\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize(args, kwds, add_initializers_to\u001b[39m=\u001b[39;49minitializers)\n\u001b[1;32m    874\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    875\u001b[0m   \u001b[39m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    876\u001b[0m   \u001b[39m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    877\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:694\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn\u001b[39m.\u001b[39m_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    692\u001b[0m \u001b[39m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[1;32m    693\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_variable_creation_fn \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 694\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_fn    \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    695\u001b[0m     \u001b[39m.\u001b[39;49m_get_concrete_function_internal_garbage_collected(\n\u001b[1;32m    696\u001b[0m         \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds))\n\u001b[1;32m    698\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvalid_creator_scope\u001b[39m(\u001b[39m*\u001b[39munused_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munused_kwds):\n\u001b[1;32m    699\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:176\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns a concrete function which cleans up its graph function.\"\"\"\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m--> 176\u001b[0m   concrete_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_concrete_function(args, kwargs)\n\u001b[1;32m    177\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:171\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m   args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_signature\n\u001b[1;32m    169\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:398\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m args \u001b[39m=\u001b[39m placeholder_bound_args\u001b[39m.\u001b[39margs\n\u001b[1;32m    396\u001b[0m kwargs \u001b[39m=\u001b[39m placeholder_bound_args\u001b[39m.\u001b[39mkwargs\n\u001b[0;32m--> 398\u001b[0m concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_concrete_function(\n\u001b[1;32m    399\u001b[0m     args, kwargs, func_graph)\n\u001b[1;32m    401\u001b[0m \u001b[39m# TODO(b/263520817): Remove access to private attribute.\u001b[39;00m\n\u001b[1;32m    402\u001b[0m graph_capture_container \u001b[39m=\u001b[39m concrete_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39mfunction_captures\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:305\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[0;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    302\u001b[0m   arg_names \u001b[39m=\u001b[39m base_arg_names\n\u001b[1;32m    304\u001b[0m concrete_function \u001b[39m=\u001b[39m monomorphic_function\u001b[39m.\u001b[39mConcreteFunction(\n\u001b[0;32m--> 305\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m    306\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[1;32m    307\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[1;32m    308\u001b[0m         args,\n\u001b[1;32m    309\u001b[0m         kwargs,\n\u001b[1;32m    310\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    311\u001b[0m         func_graph\u001b[39m=\u001b[39;49mfunc_graph,\n\u001b[1;32m    312\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[1;32m    313\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value,\n\u001b[1;32m    314\u001b[0m         create_placeholders\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m    315\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[1;32m    316\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[1;32m    317\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m    320\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    322\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1055\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1052\u001b[0m   \u001b[39mreturn\u001b[39;00m x\n\u001b[1;32m   1054\u001b[0m _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1055\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m   1057\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1059\u001b[0m func_outputs \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:597\u001b[0m, in \u001b[0;36mFunction._compiler_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    594\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    595\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    596\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 597\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39;49m__wrapped__(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    598\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py:41\u001b[0m, in \u001b[0;36mpy_func_from_autograph.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m   \u001b[39mreturn\u001b[39;00m api\u001b[39m.\u001b[39;49mconverted_call(\n\u001b[1;32m     42\u001b[0m       original_func,\n\u001b[1;32m     43\u001b[0m       args,\n\u001b[1;32m     44\u001b[0m       kwargs,\n\u001b[1;32m     45\u001b[0m       options\u001b[39m=\u001b[39;49mconverter\u001b[39m.\u001b[39;49mConversionOptions(\n\u001b[1;32m     46\u001b[0m           recursive\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     47\u001b[0m           optional_features\u001b[39m=\u001b[39;49mautograph_options,\n\u001b[1;32m     48\u001b[0m           user_requested\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     49\u001b[0m       ))\n\u001b[1;32m     50\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m     51\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file73_mh1xk.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(step_function), (ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m), ag__\u001b[39m.\u001b[39;49mld(iterator)), \u001b[39mNone\u001b[39;49;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:460\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 460\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/keras/src/engine/training.py:1322\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1318\u001b[0m     run_step \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mfunction(\n\u001b[1;32m   1319\u001b[0m         run_step, jit_compile\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, reduce_retracing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1320\u001b[0m     )\n\u001b[1;32m   1321\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(iterator)\n\u001b[0;32m-> 1322\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdistribute_strategy\u001b[39m.\u001b[39;49mrun(run_step, args\u001b[39m=\u001b[39;49m(data,))\n\u001b[1;32m   1323\u001b[0m outputs \u001b[39m=\u001b[39m reduce_per_replica(\n\u001b[1;32m   1324\u001b[0m     outputs,\n\u001b[1;32m   1325\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy,\n\u001b[1;32m   1326\u001b[0m     reduction\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_reduction_method,\n\u001b[1;32m   1327\u001b[0m )\n\u001b[1;32m   1328\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1673\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1668\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscope():\n\u001b[1;32m   1669\u001b[0m   \u001b[39m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[1;32m   1670\u001b[0m   \u001b[39m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[1;32m   1671\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[1;32m   1672\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m-> 1673\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extended\u001b[39m.\u001b[39;49mcall_for_each_replica(fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3250\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3248\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m   3249\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[0;32m-> 3250\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_for_each_replica(fn, args, kwargs)\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:4048\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   4046\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_for_each_replica\u001b[39m(\u001b[39mself\u001b[39m, fn, args, kwargs):\n\u001b[1;32m   4047\u001b[0m   \u001b[39mwith\u001b[39;00m ReplicaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[0;32m-> 4048\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 690\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    691\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    458\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    460\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/keras/src/engine/training.py:1303\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(data):\n\u001b[0;32m-> 1303\u001b[0m     outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain_step(data)\n\u001b[1;32m   1304\u001b[0m     \u001b[39m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[1;32m   1305\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/keras/src/engine/training.py:1084\u001b[0m, in \u001b[0;36mModel.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1082\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_target_and_loss(y, loss)\n\u001b[1;32m   1083\u001b[0m \u001b[39m# Run backwards pass.\u001b[39;00m\n\u001b[0;32m-> 1084\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49mminimize(loss, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainable_variables, tape\u001b[39m=\u001b[39;49mtape)\n\u001b[1;32m   1085\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_metrics(x, y, y_pred, sample_weight)\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/keras/src/optimizers/optimizer.py:544\u001b[0m, in \u001b[0;36m_BaseOptimizer.minimize\u001b[0;34m(self, loss, var_list, tape)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Minimize `loss` by updating `var_list`.\u001b[39;00m\n\u001b[1;32m    524\u001b[0m \n\u001b[1;32m    525\u001b[0m \u001b[39mThis method simply computes gradient using `tf.GradientTape` and calls\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[39m  None\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    543\u001b[0m grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_gradients(loss, var_list, tape)\n\u001b[0;32m--> 544\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_gradients(grads_and_vars)\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/keras/src/optimizers/optimizer.py:1230\u001b[0m, in \u001b[0;36mOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars, name, skip_gradients_aggregation, **kwargs)\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m skip_gradients_aggregation \u001b[39mand\u001b[39;00m experimental_aggregate_gradients:\n\u001b[1;32m   1229\u001b[0m     grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maggregate_gradients(grads_and_vars)\n\u001b[0;32m-> 1230\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mapply_gradients(grads_and_vars, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/keras/src/optimizers/optimizer.py:652\u001b[0m, in \u001b[0;36m_BaseOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_weight_decay(trainable_variables)\n\u001b[1;32m    651\u001b[0m grads_and_vars \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(grads, trainable_variables))\n\u001b[0;32m--> 652\u001b[0m iteration \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_internal_apply_gradients(grads_and_vars)\n\u001b[1;32m    654\u001b[0m \u001b[39m# Apply variable constraints after applying gradients.\u001b[39;00m\n\u001b[1;32m    655\u001b[0m \u001b[39mfor\u001b[39;00m variable \u001b[39min\u001b[39;00m trainable_variables:\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/keras/src/optimizers/optimizer.py:1260\u001b[0m, in \u001b[0;36mOptimizer._internal_apply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mesh \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_with_dtensor:\n\u001b[1;32m   1257\u001b[0m     \u001b[39m# Skip any usage of strategy logic for DTensor\u001b[39;00m\n\u001b[1;32m   1258\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m_internal_apply_gradients(grads_and_vars)\n\u001b[0;32m-> 1260\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49m__internal__\u001b[39m.\u001b[39;49mdistribute\u001b[39m.\u001b[39;49minterim\u001b[39m.\u001b[39;49mmaybe_merge_call(\n\u001b[1;32m   1261\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_distributed_apply_gradients_fn,\n\u001b[1;32m   1262\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_distribution_strategy,\n\u001b[1;32m   1263\u001b[0m     grads_and_vars,\n\u001b[1;32m   1264\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/distribute/merge_call_interim.py:51\u001b[0m, in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Maybe invoke `fn` via `merge_call` which may or may not be fulfilled.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[39mThe caller of this utility function requests to invoke `fn` via `merge_call`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39m  The return value of the `fn` call.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39mif\u001b[39;00m strategy_supports_no_merge_call():\n\u001b[0;32m---> 51\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(strategy, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   \u001b[39mreturn\u001b[39;00m distribute_lib\u001b[39m.\u001b[39mget_replica_context()\u001b[39m.\u001b[39mmerge_call(\n\u001b[1;32m     54\u001b[0m       fn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/keras/src/optimizers/optimizer.py:1352\u001b[0m, in \u001b[0;36mOptimizer._distributed_apply_gradients_fn\u001b[0;34m(self, distribution, grads_and_vars, **kwargs)\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_step(grad, var)\n\u001b[1;32m   1351\u001b[0m \u001b[39mfor\u001b[39;00m grad, var \u001b[39min\u001b[39;00m grads_and_vars:\n\u001b[0;32m-> 1352\u001b[0m     distribution\u001b[39m.\u001b[39;49mextended\u001b[39m.\u001b[39;49mupdate(\n\u001b[1;32m   1353\u001b[0m         var, apply_grad_to_update_var, args\u001b[39m=\u001b[39;49m(grad,), group\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m   1354\u001b[0m     )\n\u001b[1;32m   1356\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_ema:\n\u001b[1;32m   1357\u001b[0m     _, var_list \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mgrads_and_vars)\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2994\u001b[0m, in \u001b[0;36mStrategyExtendedV2.update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2992\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update(var, fn, args, kwargs, group)\n\u001b[1;32m   2993\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2994\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_replica_ctx_update(\n\u001b[1;32m   2995\u001b[0m       var, fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs, group\u001b[39m=\u001b[39;49mgroup)\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2873\u001b[0m, in \u001b[0;36mStrategyExtendedV2._replica_ctx_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2870\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge_fn\u001b[39m(_, \u001b[39m*\u001b[39mmerged_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmerged_kwargs):\n\u001b[1;32m   2871\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate(var, fn, merged_args, merged_kwargs, group\u001b[39m=\u001b[39mgroup)\n\u001b[0;32m-> 2873\u001b[0m \u001b[39mreturn\u001b[39;00m replica_context\u001b[39m.\u001b[39;49mmerge_call(merge_fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3465\u001b[0m, in \u001b[0;36mReplicaContextBase.merge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m   3463\u001b[0m merge_fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[1;32m   3464\u001b[0m     merge_fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m-> 3465\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_merge_call(merge_fn, args, kwargs)\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3472\u001b[0m, in \u001b[0;36mReplicaContextBase._merge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3469\u001b[0m _push_per_thread_mode(  \u001b[39m# thread-local, so not needed with multiple threads\u001b[39;00m\n\u001b[1;32m   3470\u001b[0m     _CrossReplicaThreadMode(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_strategy))  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   3471\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3472\u001b[0m   \u001b[39mreturn\u001b[39;00m merge_fn(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_strategy, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   3473\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   3474\u001b[0m   _pop_per_thread_mode()\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 690\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    691\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    458\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    460\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2871\u001b[0m, in \u001b[0;36mStrategyExtendedV2._replica_ctx_update.<locals>.merge_fn\u001b[0;34m(_, *merged_args, **merged_kwargs)\u001b[0m\n\u001b[1;32m   2870\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge_fn\u001b[39m(_, \u001b[39m*\u001b[39mmerged_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmerged_kwargs):\n\u001b[0;32m-> 2871\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate(var, fn, merged_args, merged_kwargs, group\u001b[39m=\u001b[39;49mgroup)\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2992\u001b[0m, in \u001b[0;36mStrategyExtendedV2.update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2989\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[1;32m   2990\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   2991\u001b[0m   \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[0;32m-> 2992\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update(var, fn, args, kwargs, group)\n\u001b[1;32m   2993\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2994\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_replica_ctx_update(\n\u001b[1;32m   2995\u001b[0m       var, fn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs, group\u001b[39m=\u001b[39mgroup)\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:4062\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   4059\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update\u001b[39m(\u001b[39mself\u001b[39m, var, fn, args, kwargs, group):\n\u001b[1;32m   4060\u001b[0m   \u001b[39m# The implementations of _update() and _update_non_slot() are identical\u001b[39;00m\n\u001b[1;32m   4061\u001b[0m   \u001b[39m# except _update() passes `var` as the first argument to `fn()`.\u001b[39;00m\n\u001b[0;32m-> 4062\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_non_slot(var, fn, (var,) \u001b[39m+\u001b[39;49m \u001b[39mtuple\u001b[39;49m(args), kwargs, group)\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:4068\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   4064\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_non_slot\u001b[39m(\u001b[39mself\u001b[39m, colocate_with, fn, args, kwargs, should_group):\n\u001b[1;32m   4065\u001b[0m   \u001b[39m# TODO(josh11b): Figure out what we should be passing to UpdateContext()\u001b[39;00m\n\u001b[1;32m   4066\u001b[0m   \u001b[39m# once that value is used for something.\u001b[39;00m\n\u001b[1;32m   4067\u001b[0m   \u001b[39mwith\u001b[39;00m UpdateContext(colocate_with):\n\u001b[0;32m-> 4068\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   4069\u001b[0m     \u001b[39mif\u001b[39;00m should_group:\n\u001b[1;32m   4070\u001b[0m       \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 690\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    691\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[1;32m    330\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: from cache\u001b[39m\u001b[39m'\u001b[39m, f)\n\u001b[0;32m--> 331\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    333\u001b[0m \u001b[39mif\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m ag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED:\n\u001b[1;32m    334\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: AutoGraph is disabled in context\u001b[39m\u001b[39m'\u001b[39m, f)\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    458\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    460\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/keras/src/optimizers/optimizer.py:1349\u001b[0m, in \u001b[0;36mOptimizer._distributed_apply_gradients_fn.<locals>.apply_grad_to_update_var\u001b[0;34m(var, grad)\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_step_xla(grad, var, \u001b[39mid\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_var_key(var)))\n\u001b[1;32m   1348\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1349\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_step(grad, var)\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/keras/src/optimizers/optimizer.py:241\u001b[0m, in \u001b[0;36m_BaseOptimizer._update_step\u001b[0;34m(self, gradient, variable)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_var_key(variable) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_dict:\n\u001b[1;32m    233\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\n\u001b[1;32m    234\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe optimizer cannot recognize variable \u001b[39m\u001b[39m{\u001b[39;00mvariable\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    235\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis usually means you are trying to call the optimizer to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`tf.keras.optimizers.legacy.\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    240\u001b[0m     )\n\u001b[0;32m--> 241\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate_step(gradient, variable)\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/keras/src/optimizers/adam.py:198\u001b[0m, in \u001b[0;36mAdam.update_step\u001b[0;34m(self, gradient, variable)\u001b[0m\n\u001b[1;32m    195\u001b[0m     variable\u001b[39m.\u001b[39massign_sub((m \u001b[39m*\u001b[39m alpha) \u001b[39m/\u001b[39m (tf\u001b[39m.\u001b[39msqrt(v) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepsilon))\n\u001b[1;32m    196\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m     \u001b[39m# Dense gradients.\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m     m\u001b[39m.\u001b[39massign_add((gradient \u001b[39m-\u001b[39;49m m) \u001b[39m*\u001b[39;49m (\u001b[39m1\u001b[39;49m \u001b[39m-\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbeta_1))\n\u001b[1;32m    199\u001b[0m     v\u001b[39m.\u001b[39massign_add((tf\u001b[39m.\u001b[39msquare(gradient) \u001b[39m-\u001b[39m v) \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbeta_2))\n\u001b[1;32m    200\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mamsgrad:\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py:1466\u001b[0m, in \u001b[0;36m_OverrideBinaryOperatorHelper.<locals>.binary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1461\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1462\u001b[0m   \u001b[39m# force_same_dtype=False to preserve existing TF behavior\u001b[39;00m\n\u001b[1;32m   1463\u001b[0m   \u001b[39m# TODO(b/178860388): Figure out why binary_op_wrapper and\u001b[39;00m\n\u001b[1;32m   1464\u001b[0m   \u001b[39m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[39;00m\n\u001b[1;32m   1465\u001b[0m   x, y \u001b[39m=\u001b[39m maybe_promote_tensors(x, y)\n\u001b[0;32m-> 1466\u001b[0m   \u001b[39mreturn\u001b[39;00m func(x, y, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m   1467\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1468\u001b[0m   \u001b[39m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[39;00m\n\u001b[1;32m   1469\u001b[0m   \u001b[39m# object that can implement the operator with knowledge of itself\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1472\u001b[0m   \u001b[39m# original error from the LHS, because it may be more\u001b[39;00m\n\u001b[1;32m   1473\u001b[0m   \u001b[39m# informative.\u001b[39;00m\n\u001b[1;32m   1474\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mtype\u001b[39m(y), \u001b[39m\"\u001b[39m\u001b[39m__r\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m__\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m op_name):\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py:1847\u001b[0m, in \u001b[0;36m_mul_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1845\u001b[0m   \u001b[39mreturn\u001b[39;00m sparse_tensor\u001b[39m.\u001b[39mSparseTensor(y\u001b[39m.\u001b[39mindices, new_vals, y\u001b[39m.\u001b[39mdense_shape)\n\u001b[1;32m   1846\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1847\u001b[0m   \u001b[39mreturn\u001b[39;00m multiply(x, y, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py:530\u001b[0m, in \u001b[0;36mmultiply\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mmath.multiply\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmultiply\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    482\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39mregister_binary_elementwise_api\n\u001b[1;32m    483\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[1;32m    484\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmultiply\u001b[39m(x, y, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    485\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Returns an element-wise x * y.\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \n\u001b[1;32m    487\u001b[0m \u001b[39m  For example:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[39m   * InvalidArgumentError: When `x` and `y` have incompatible shapes or types.\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 530\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_math_ops\u001b[39m.\u001b[39;49mmul(x, y, name)\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py:6590\u001b[0m, in \u001b[0;36mmul\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   6588\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[1;32m   6589\u001b[0m \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[0;32m-> 6590\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[1;32m   6591\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mMul\u001b[39;49m\u001b[39m\"\u001b[39;49m, x\u001b[39m=\u001b[39;49mx, y\u001b[39m=\u001b[39;49my, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m   6592\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[1;32m   6593\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py:775\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    770\u001b[0m   _ExtractDefaultTypesAndAllowedTypes(op_def, default_type_attr_map,\n\u001b[1;32m    771\u001b[0m                                       allowed_list_attr_map)\n\u001b[1;32m    773\u001b[0m \u001b[39m# Requires that op_def has passed validation (using the C++\u001b[39;00m\n\u001b[1;32m    774\u001b[0m \u001b[39m# ValidateOpDef() from ../framework/op_def_util.h).\u001b[39;00m\n\u001b[0;32m--> 775\u001b[0m \u001b[39mwith\u001b[39;00m g\u001b[39m.\u001b[39;49mas_default(), ops\u001b[39m.\u001b[39mname_scope(name) \u001b[39mas\u001b[39;00m scope:\n\u001b[1;32m    776\u001b[0m   \u001b[39mif\u001b[39;00m fallback:\n\u001b[1;32m    777\u001b[0m     _ExtractInputsAndAttrs(op_type_name, op_def, allowed_list_attr_map,\n\u001b[1;32m    778\u001b[0m                            keywords, default_type_attr_map, attrs, inputs,\n\u001b[1;32m    779\u001b[0m                            input_types)\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:442\u001b[0m, in \u001b[0;36mFuncGraph.as_default\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    439\u001b[0m       filtered_control_inputs\u001b[39m.\u001b[39mappend(graph_element)\n\u001b[1;32m    440\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mcontrol_dependencies(filtered_control_inputs)\n\u001b[0;32m--> 442\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mas_default\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    443\u001b[0m   outer_cm \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mas_default()\n\u001b[1;32m    445\u001b[0m   \u001b[39m@tf_contextlib\u001b[39m\u001b[39m.\u001b[39mcontextmanager\n\u001b[1;32m    446\u001b[0m   \u001b[39mdef\u001b[39;00m \u001b[39minner_cm\u001b[39m():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#run call the transformer model\n",
    "#df_read = df.copy()\n",
    "#df_read=(df_read-df_read.mean())/df_read.std()\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#train, test = train_test_split(df_read, test_size=0.2)\n",
    "\n",
    "train = pd.concat([df1,df2,df3,df4], axis=0)\n",
    "test = df5.copy()\n",
    "\n",
    "Y_train = np.array(train['class'])\n",
    "X_train= np.array(train.drop(['0', 'class'],axis=1))\n",
    "X_train=X_train.reshape(X_train.shape[0], 1 , X_train.shape[1])\n",
    "print(X_train.shape[1])\n",
    "print(X_train.shape)\n",
    "\n",
    "Y_val=np.array(test['class'])\n",
    "X_val = np.array(test.drop(['0', 'class'],axis=1))\n",
    "X_val=X_val.reshape(X_val.shape[0], 1 , X_val.shape[1])\n",
    "NUM_LAYERS =  4\n",
    "\n",
    "D_MODEL = X_train.shape[2]\n",
    "print('d_model', D_MODEL)\n",
    "NUM_HEADS =  4\n",
    "print('num_heads', NUM_HEADS)\n",
    "UNITS =  2048\n",
    "DROPOUT = 0.1 #0.1\n",
    "TIME_STEPS= X_train.shape[1]\n",
    "print('TIME STEPS', TIME_STEPS)\n",
    "OUTPUT_SIZE=1\n",
    "batch_size=64\n",
    "\n",
    "model = transformer(\n",
    "  time_steps=TIME_STEPS,\n",
    "  num_layers=NUM_LAYERS,\n",
    "  units=UNITS,\n",
    "  d_model=D_MODEL,\n",
    "  num_heads=NUM_HEADS,\n",
    "  dropout=DROPOUT,\n",
    "  output_size=OUTPUT_SIZE,\n",
    "  projection='linear')\n",
    "\n",
    "#run\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(0.00005), loss='mae') #org\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.000003), loss='mse')\n",
    "# model.compile(optimizer=tf.keras.optimizers.SGD(0.01), loss='mae')\n",
    "#\n",
    "# callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience=80, restore_best_weights=True)\n",
    "# history = model.fit(X_train,Y_train, epochs=1000, validation_data=(X_val, Y_val), callbacks=[callback])\n",
    "history = model.fit(X_train,Y_train, epochs=1000, validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UxMyaAwpcqdf",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0005130066929093327\n",
      "(1660, 1, 176)\n",
      "(415, 1, 176)\n"
     ]
    }
   ],
   "source": [
    "#run\n",
    "import time\n",
    "st = time.time()\n",
    "p1 = np.array(model(X_val)).flatten()\n",
    "end = time.time()\n",
    "# print(end, st, len(p1))\n",
    "print((end-st)/len(p1))\n",
    "p2 = np.array(model(X_train)).flatten()\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Say3gnZgi331",
    "outputId": "8cb662ec-46e3-428c-a3dc-5f3adeb2ff3a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'p2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ashutosh/Desktop/ugmqa_project/notebooks/cross_attention_with_1_head.ipynb Cell 19\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ashutosh/Desktop/ugmqa_project/notebooks/cross_attention_with_1_head.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstats\u001b[39;00m \u001b[39mimport\u001b[39;00m kendalltau\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ashutosh/Desktop/ugmqa_project/notebooks/cross_attention_with_1_head.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ashutosh/Desktop/ugmqa_project/notebooks/cross_attention_with_1_head.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39mcorrcoef(p2, Y_train), stats\u001b[39m.\u001b[39mspearmanr(p2, Y_train), kendalltau(p2,Y_train)\u001b[39m.\u001b[39mcorrelation)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ashutosh/Desktop/ugmqa_project/notebooks/cross_attention_with_1_head.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mValidation\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ashutosh/Desktop/ugmqa_project/notebooks/cross_attention_with_1_head.ipynb#X24sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39mcorrcoef(p1, Y_val)[\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m], stats\u001b[39m.\u001b[39mspearmanr(p1, Y_val)\u001b[39m.\u001b[39mcorrelation, kendalltau(p1,Y_val)\u001b[39m.\u001b[39mcorrelation)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'p2' is not defined"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from scipy.stats import kendalltau\n",
    "print(\"training\")\n",
    "print(np.corrcoef(p2, Y_train), stats.spearmanr(p2, Y_train), kendalltau(p2,Y_train).correlation)\n",
    "print(\"Validation\")\n",
    "print(np.corrcoef(p1, Y_val)[1][0], stats.spearmanr(p1, Y_val).correlation, kendalltau(p1,Y_val).correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ST5WiH4KoeOh",
    "outputId": "b995e4a2-4e2a-412c-9c59-0ee632503d82",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1660, 1, 176)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "ksXNLzMScqg6",
    "outputId": "218ba87c-4fe6-43c8-bf76-19bc5d9ce9b8",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#run\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.savefig(\"audio_dm_3_featu_.jpg\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

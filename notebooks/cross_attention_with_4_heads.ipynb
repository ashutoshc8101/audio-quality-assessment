{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nXRPF7T0b-QZ",
    "outputId": "821fc7ca-79e6-4cf6-e81d-37fd685b71f3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spafe in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (0.3.2)\n",
      "Requirement already satisfied: pandas in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (2.0.3)\n",
      "Requirement already satisfied: tensorflow in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (2.13.1)\n",
      "Requirement already satisfied: seaborn in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (0.13.0)\n",
      "Requirement already satisfied: opencv-python in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (4.8.1.78)\n",
      "Requirement already satisfied: tqdm in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (4.66.1)\n",
      "Requirement already satisfied: librosa in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (0.10.1)\n",
      "Requirement already satisfied: typing-extensions in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from spafe) (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.21 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from spafe) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.7.3 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from spafe) (1.10.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: packaging in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from tensorflow) (0.34.0)\n",
      "Requirement already satisfied: setuptools in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from tensorflow) (56.0.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from tensorflow) (1.59.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from tensorflow) (4.24.4)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from tensorflow) (2.0.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from tensorflow) (2.13.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.3 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from seaborn) (3.7.3)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from librosa) (1.3.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from librosa) (0.58.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from librosa) (0.3)\n",
      "Requirement already satisfied: pooch>=1.0 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from librosa) (1.7.0)\n",
      "Requirement already satisfied: msgpack>=1.0 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from librosa) (1.0.7)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from librosa) (0.3.7)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: joblib>=0.14 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from librosa) (1.3.2)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (10.0.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (6.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (3.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.1.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.4.5)\n",
      "Requirement already satisfied: importlib-metadata in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from numba>=0.51.0->librosa) (6.8.0)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from numba>=0.51.0->librosa) (0.41.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from pooch>=1.0->librosa) (3.11.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from pooch>=1.0->librosa) (2.31.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.5)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.23.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: pycparser in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.3->seaborn) (3.17.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ashutosh/Desktop/ugmqa_project/venv/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/home/ashutosh/Desktop/ugmqa_project/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#run\n",
    "!pip install spafe pandas tensorflow seaborn opencv-python tqdm librosa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "s2K5aSHYb-Sm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#run\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import defaultdict\n",
    "from spafe.utils import vis\n",
    "from spafe.features.lfcc import lfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-xNIFhPtb-U5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-15 22:40:03.644195: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#run\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "QgbvNKYAb-YM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import ResNet50,ResNet101\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.model_selection import StratifiedKFold , KFold ,RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "LXsQV7ivcIcc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#run\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # add the mask zero out padding tokens.\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  return tf.matmul(attention_weights, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7WB2_09_e-qt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#run\n",
    "# This allows to the transformer to know where there is real data and where it is padded\n",
    "def create_padding_mask(seq):\n",
    "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "  # add extra dimensions to add the padding\n",
    "  # to the attention logits.\n",
    "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PjEQIR8TcIe3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#run\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # linear layers\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # split heads\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8hF4xYdLcSQA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#run\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "    # apply sin to even index in the array\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # apply cos to odd index in the array\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "j7ewC3iBcSSo",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#run\n",
    "def encoder_layer(units, d_model, num_heads, dropout,name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,d_model ), name=\"inputs\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "  print(padding_mask)\n",
    "\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention1\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "  attention1 = tf.keras.layers.Dropout(rate=dropout)(attention1)\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention1)\n",
    "    \n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention2\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention2)\n",
    "\n",
    "  attention3 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention3\")({\n",
    "          'query': attention1,\n",
    "          'key': attention2,\n",
    "          'value': attention1,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "  attention3 = tf.keras.layers.Dropout(rate=dropout)(attention3)\n",
    "  attention3 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention3)\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention3)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  # outputs = tf.keras.layers.LayerNormalization(\n",
    "  #     epsilon=1e-6)(attention3 + outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention3)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_8IFloblcSWJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#run\n",
    "def encoder(time_steps,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            projection,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,d_model), name=\"inputs\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  if projection=='linear':\n",
    "    ## We implement a linear projection based on Very Deep Self-Attention Networks for End-to-End Speech Recognition. Retrieved from https://arxiv.org/abs/1904.13377\n",
    "    projection=tf.keras.layers.Dense( d_model,use_bias=True, activation='linear')(inputs)\n",
    "    print('linear')\n",
    "\n",
    "  else:\n",
    "    projection=tf.identity(inputs)\n",
    "    print('none')\n",
    "\n",
    "  projection *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "  projection = PositionalEncoding(time_steps, d_model)(projection)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(projection)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "NXgJh2PpcIiK",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#run\n",
    "def transformer(time_steps,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                output_size,\n",
    "                projection,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,d_model), name=\"inputs\")\n",
    "\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(tf.dtypes.cast(\n",
    "\n",
    "      #Like our input has a dimension of length X d_model but the masking is applied to a vector\n",
    "      # We get the sum for each row and result is a vector. So, if result is 0 it is because in that position was masked\n",
    "      tf.math.reduce_sum(\n",
    "      inputs,\n",
    "      axis=2,\n",
    "      keepdims=False,\n",
    "      name=None\n",
    "  ), tf.int32))\n",
    "\n",
    "  enc_outputs = encoder(\n",
    "      time_steps=time_steps,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "      projection=projection,\n",
    "      name='encoder'\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  #We reshape for feeding our FC in the next step\n",
    "  outputs = tf.reshape(enc_outputs,(-1,time_steps*d_model))\n",
    "\n",
    "  #We predict our class\n",
    "  outputs = tf.keras.layers.Dense(units=output_size,use_bias=True, name=\"outputs\")(outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs], outputs=outputs, name='audio_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "9H-kkyuLcbPZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#run\n",
    "# num_batch_size = 32\n",
    "# num_epochs = 500\n",
    "# N_SPLIT = 10\n",
    "# num_labels=5\n",
    "# num_classes=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u4Iw3KzecbRt",
    "outputId": "0ffe72e2-2c24-4cbd-9441-a681fcf507e4",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2075, 298)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ajit\n",
    "# df = pd.read_csv('/content/drive/MyDrive/DatabaseDistorted/final_tii_all_finaldata/features/2075_concatenate5_spectral2.csv')\n",
    "# dm\n",
    "# df = pd.read_csv('./DatabaseDistorted/final_tii_all_finaldata/features/2075_concatenate_dm.csv')\n",
    "df = pd.read_csv('./audio_features.csv')\n",
    "\n",
    "\n",
    "# df = pd.read_csv('/content/drive/MyDrive/DatabaseDistorted/final_tii_all_finaldata/features/melspectogram_mean_newdm_2075.csv')\n",
    "# df = pd.read_csv('/content/drive/MyDrive/DatabaseDistorted/final_tii_all_finaldata/features/chroma_cqt_simple_mean_newdm_2075.csv')\n",
    "# df = pd.read_csv('/content/drive/MyDrive/DatabaseDistorted/final_tii_all_finaldata/features/mfcc_simple_mean_newdm_2075.csv')\n",
    "# df = pd.read_csv('/content/drive/MyDrive/DatabaseDistorted/final_tii_all_finaldata/features/spectral_centroid_meandm_2075_200.csv')\n",
    "\n",
    "df = df.drop(['Unnamed: 0'], axis = 1)\n",
    "df = df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2HrbtbLXcbTx",
    "outputId": "7a1af2ba-848e-44d8-d239-a2518c22f9bd",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(415, 298)\n",
      "(415, 298)\n",
      "(415, 298)\n",
      "(415, 298)\n",
      "(415, 298)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "siz=415\n",
    "df_read = df.copy()\n",
    "df1 = df_read.sample(siz)\n",
    "df_read = df_read.drop(df1.index)\n",
    "df2 = df_read.sample(siz)\n",
    "df_read = df_read.drop(df2.index)\n",
    "df3 = df_read.sample(siz)\n",
    "df_read = df_read.drop(df3.index)\n",
    "df4 = df_read.sample(siz)\n",
    "df_read = df_read.drop(df4.index)\n",
    "df5 = df_read.copy()\n",
    "\n",
    "print(df1.shape)\n",
    "print(df2.shape)\n",
    "print(df3.shape)\n",
    "print(df4.shape)\n",
    "print(df5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_j19bgqpcbWT",
    "outputId": "e4e9f119-b436-44fe-ab74-572cf6d7bca3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([ 881,  453, 2004, 1353,  281,  941, 1185, 1159, 1138,  599,\n",
      "       ...\n",
      "        834, 1730,  353, 1345, 1190, 1375,  185,  701, 1671, 1982],\n",
      "      dtype='int64', length=415)\n"
     ]
    }
   ],
   "source": [
    "q = list(df1.index)+list(df2.index)+list(df3.index)+list(df4.index)+list(df5.index)\n",
    "print(df1.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>288</th>\n",
       "      <th>289</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>115.100464</td>\n",
       "      <td>116.435690</td>\n",
       "      <td>-33.895737</td>\n",
       "      <td>21.440712</td>\n",
       "      <td>-8.445481</td>\n",
       "      <td>-2.221351</td>\n",
       "      <td>-5.662595</td>\n",
       "      <td>-5.307188</td>\n",
       "      <td>-3.395119</td>\n",
       "      <td>1.959972</td>\n",
       "      <td>...</td>\n",
       "      <td>1924.734414</td>\n",
       "      <td>2214.323973</td>\n",
       "      <td>2369.313522</td>\n",
       "      <td>1993.016083</td>\n",
       "      <td>1656.398893</td>\n",
       "      <td>1712.388520</td>\n",
       "      <td>1877.955538</td>\n",
       "      <td>2202.385976</td>\n",
       "      <td>2197.057367</td>\n",
       "      <td>1.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>-81.505840</td>\n",
       "      <td>93.929110</td>\n",
       "      <td>2.407967</td>\n",
       "      <td>5.197178</td>\n",
       "      <td>-4.273181</td>\n",
       "      <td>15.114481</td>\n",
       "      <td>-12.457763</td>\n",
       "      <td>-2.422184</td>\n",
       "      <td>-10.028605</td>\n",
       "      <td>11.997586</td>\n",
       "      <td>...</td>\n",
       "      <td>2165.990403</td>\n",
       "      <td>2121.735482</td>\n",
       "      <td>2169.657425</td>\n",
       "      <td>2299.472756</td>\n",
       "      <td>2309.287640</td>\n",
       "      <td>2272.999651</td>\n",
       "      <td>2427.676392</td>\n",
       "      <td>2451.911800</td>\n",
       "      <td>2408.656902</td>\n",
       "      <td>1.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>-301.374900</td>\n",
       "      <td>286.829930</td>\n",
       "      <td>-56.174410</td>\n",
       "      <td>-25.532795</td>\n",
       "      <td>53.723870</td>\n",
       "      <td>-20.187690</td>\n",
       "      <td>-24.548950</td>\n",
       "      <td>25.045732</td>\n",
       "      <td>-8.054552</td>\n",
       "      <td>-20.254957</td>\n",
       "      <td>...</td>\n",
       "      <td>902.227666</td>\n",
       "      <td>895.068748</td>\n",
       "      <td>792.717657</td>\n",
       "      <td>816.468468</td>\n",
       "      <td>821.499510</td>\n",
       "      <td>797.085182</td>\n",
       "      <td>830.891295</td>\n",
       "      <td>837.543881</td>\n",
       "      <td>856.526688</td>\n",
       "      <td>1.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>-354.598450</td>\n",
       "      <td>259.105130</td>\n",
       "      <td>120.287290</td>\n",
       "      <td>-6.172213</td>\n",
       "      <td>-55.095108</td>\n",
       "      <td>-30.534496</td>\n",
       "      <td>13.320685</td>\n",
       "      <td>27.653042</td>\n",
       "      <td>7.574259</td>\n",
       "      <td>-16.686695</td>\n",
       "      <td>...</td>\n",
       "      <td>541.573084</td>\n",
       "      <td>527.706392</td>\n",
       "      <td>516.779659</td>\n",
       "      <td>516.765627</td>\n",
       "      <td>550.828158</td>\n",
       "      <td>547.339139</td>\n",
       "      <td>551.372349</td>\n",
       "      <td>539.345737</td>\n",
       "      <td>516.670265</td>\n",
       "      <td>1.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>13.566546</td>\n",
       "      <td>20.589693</td>\n",
       "      <td>16.374050</td>\n",
       "      <td>13.352259</td>\n",
       "      <td>7.065914</td>\n",
       "      <td>7.064869</td>\n",
       "      <td>3.771653</td>\n",
       "      <td>3.909107</td>\n",
       "      <td>1.383886</td>\n",
       "      <td>4.150478</td>\n",
       "      <td>...</td>\n",
       "      <td>4835.892625</td>\n",
       "      <td>4971.914880</td>\n",
       "      <td>5068.061026</td>\n",
       "      <td>4916.267485</td>\n",
       "      <td>4950.245484</td>\n",
       "      <td>5003.574506</td>\n",
       "      <td>4919.739213</td>\n",
       "      <td>4890.999577</td>\n",
       "      <td>5021.892732</td>\n",
       "      <td>1.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 298 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2          3          4          5  \\\n",
       "881   115.100464  116.435690  -33.895737  21.440712  -8.445481  -2.221351   \n",
       "453   -81.505840   93.929110    2.407967   5.197178  -4.273181  15.114481   \n",
       "2004 -301.374900  286.829930  -56.174410 -25.532795  53.723870 -20.187690   \n",
       "1353 -354.598450  259.105130  120.287290  -6.172213 -55.095108 -30.534496   \n",
       "281    13.566546   20.589693   16.374050  13.352259   7.065914   7.064869   \n",
       "\n",
       "              6          7          8          9  ...          288  \\\n",
       "881   -5.662595  -5.307188  -3.395119   1.959972  ...  1924.734414   \n",
       "453  -12.457763  -2.422184 -10.028605  11.997586  ...  2165.990403   \n",
       "2004 -24.548950  25.045732  -8.054552 -20.254957  ...   902.227666   \n",
       "1353  13.320685  27.653042   7.574259 -16.686695  ...   541.573084   \n",
       "281    3.771653   3.909107   1.383886   4.150478  ...  4835.892625   \n",
       "\n",
       "              289          290          291          292          293  \\\n",
       "881   2214.323973  2369.313522  1993.016083  1656.398893  1712.388520   \n",
       "453   2121.735482  2169.657425  2299.472756  2309.287640  2272.999651   \n",
       "2004   895.068748   792.717657   816.468468   821.499510   797.085182   \n",
       "1353   527.706392   516.779659   516.765627   550.828158   547.339139   \n",
       "281   4971.914880  5068.061026  4916.267485  4950.245484  5003.574506   \n",
       "\n",
       "              294          295          296  class  \n",
       "881   1877.955538  2202.385976  2197.057367   1.61  \n",
       "453   2427.676392  2451.911800  2408.656902   1.15  \n",
       "2004   830.891295   837.543881   856.526688   1.76  \n",
       "1353   551.372349   539.345737   516.670265   1.24  \n",
       "281   4919.739213  4890.999577  5021.892732   1.08  \n",
       "\n",
       "[5 rows x 298 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.concat([df1,df2,df3,df4], axis=0)\n",
    "train = train.dropna()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uT0Jrfa5cbZv",
    "outputId": "765d52d9-b8e2-4f6d-cd94-261bb7f7c39d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(1660, 1, 296)\n",
      "d_model 296\n",
      "num_heads 4\n",
      "TIME STEPS 1\n",
      "linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-15 22:40:06.179230: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-15 22:40:06.181914: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, None), dtype=tf.float32, name='padding_mask'), name='padding_mask', description=\"created by layer 'padding_mask'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, None), dtype=tf.float32, name='padding_mask'), name='padding_mask', description=\"created by layer 'padding_mask'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, None), dtype=tf.float32, name='padding_mask'), name='padding_mask', description=\"created by layer 'padding_mask'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, None), dtype=tf.float32, name='padding_mask'), name='padding_mask', description=\"created by layer 'padding_mask'\")\n",
      "Epoch 1/1000\n",
      "52/52 [==============================] - 14s 56ms/step - loss: 6.2967 - val_loss: 1.9127\n",
      "Epoch 2/1000\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 2.3748 - val_loss: 2.1248\n",
      "Epoch 3/1000\n",
      "52/52 [==============================] - 1s 29ms/step - loss: 2.3751 - val_loss: 2.0158\n",
      "Epoch 4/1000\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 2.2608 - val_loss: 1.9753\n",
      "Epoch 5/1000\n",
      "52/52 [==============================] - 1s 29ms/step - loss: 2.2557 - val_loss: 1.9665\n",
      "Epoch 6/1000\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 2.1191 - val_loss: 1.9394\n",
      "Epoch 7/1000\n",
      " 1/52 [..............................] - ETA: 1s - loss: 2.3953"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ashutosh/Desktop/ugmqa_project/notebooks/cross_attention_with_4_heads.ipynb Cell 17\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ashutosh/Desktop/ugmqa_project/notebooks/cross_attention_with_4_heads.ipynb#X22sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(\u001b[39m0.000003\u001b[39m), loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ashutosh/Desktop/ugmqa_project/notebooks/cross_attention_with_4_heads.ipynb#X22sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39m# model.compile(optimizer=tf.keras.optimizers.SGD(0.01), loss='mae')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ashutosh/Desktop/ugmqa_project/notebooks/cross_attention_with_4_heads.ipynb#X22sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ashutosh/Desktop/ugmqa_project/notebooks/cross_attention_with_4_heads.ipynb#X22sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m# callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience=80, restore_best_weights=True)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ashutosh/Desktop/ugmqa_project/notebooks/cross_attention_with_4_heads.ipynb#X22sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39m# history = model.fit(X_train,Y_train, epochs=1000, validation_data=(X_val, Y_val), callbacks=[callback])\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ashutosh/Desktop/ugmqa_project/notebooks/cross_attention_with_4_heads.ipynb#X22sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train,Y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_val, Y_val))\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#run call the transformer model\n",
    "#df_read = df.copy()\n",
    "#df_read=(df_read-df_read.mean())/df_read.std()\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#train, test = train_test_split(df_read, test_size=0.2)\n",
    "\n",
    "train = pd.concat([df1,df2,df3,df4], axis=0)\n",
    "test = df5.copy()\n",
    "\n",
    "Y_train = np.array(train['class'])\n",
    "X_train= np.array(train.drop(['0', 'class'],axis=1))\n",
    "X_train=X_train.reshape(X_train.shape[0], 1 , X_train.shape[1])\n",
    "print(X_train.shape[1])\n",
    "print(X_train.shape)\n",
    "\n",
    "Y_val=np.array(test['class'])\n",
    "X_val = np.array(test.drop(['0', 'class'],axis=1))\n",
    "X_val=X_val.reshape(X_val.shape[0], 1 , X_val.shape[1])\n",
    "NUM_LAYERS =  4\n",
    "\n",
    "D_MODEL = X_train.shape[2]\n",
    "print('d_model', D_MODEL)\n",
    "NUM_HEADS =  4\n",
    "print('num_heads', NUM_HEADS)\n",
    "UNITS =  2048\n",
    "DROPOUT = 0.1 #0.1\n",
    "TIME_STEPS= X_train.shape[1]\n",
    "print('TIME STEPS', TIME_STEPS)\n",
    "OUTPUT_SIZE=1\n",
    "batch_size=64\n",
    "\n",
    "model = transformer(\n",
    "  time_steps=TIME_STEPS,\n",
    "  num_layers=NUM_LAYERS,\n",
    "  units=UNITS,\n",
    "  d_model=D_MODEL,\n",
    "  num_heads=NUM_HEADS,\n",
    "  dropout=DROPOUT,\n",
    "  output_size=OUTPUT_SIZE,\n",
    "  projection='linear')\n",
    "\n",
    "#run\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(0.00005), loss='mae') #org\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.000003), loss='mse')\n",
    "# model.compile(optimizer=tf.keras.optimizers.SGD(0.01), loss='mae')\n",
    "#\n",
    "# callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience=80, restore_best_weights=True)\n",
    "# history = model.fit(X_train,Y_train, epochs=1000, validation_data=(X_val, Y_val), callbacks=[callback])\n",
    "history = model.fit(X_train,Y_train, epochs=1000, validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UxMyaAwpcqdf",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00037309520215873256\n",
      "(1660, 1, 176)\n",
      "(415, 1, 176)\n"
     ]
    }
   ],
   "source": [
    "#run\n",
    "import time\n",
    "st = time.time()\n",
    "p1 = np.array(model(X_val)).flatten()\n",
    "end = time.time()\n",
    "# print(end, st, len(p1))\n",
    "print((end-st)/len(p1))\n",
    "p2 = np.array(model(X_train)).flatten()\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Say3gnZgi331",
    "outputId": "8cb662ec-46e3-428c-a3dc-5f3adeb2ff3a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "[[1.         0.823123123]\n",
      " [0.821123123 1.        ]] SignificanceResult(statistic=0.7493208976225663, pvalue=4.2164156017597297e-299) 0.5537683816473855\n",
      "Validation\n",
      "0.82312231213213 0.8215096819894705 0.6192355721849291\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from scipy.stats import kendalltau\n",
    "print(\"training\")\n",
    "print(np.corrcoef(p2, Y_train), stats.spearmanr(p2, Y_train), kendalltau(p2,Y_train).correlation)\n",
    "print(\"Validation\")\n",
    "print(np.corrcoef(p1, Y_val)[1][0], stats.spearmanr(p1, Y_val).correlation, kendalltau(p1,Y_val).correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ST5WiH4KoeOh",
    "outputId": "b995e4a2-4e2a-412c-9c59-0ee632503d82",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1660, 1, 176)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "ksXNLzMScqg6",
    "outputId": "218ba87c-4fe6-43c8-bf76-19bc5d9ce9b8",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAG0CAYAAADO5AZFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABS1UlEQVR4nO3dd3xUVd7H8c+dmWRSSAIEUpDQBCmhSFEIooIoUiwodlTUZ3VRQFkWC7r2El1dl2V1QVxEWVTURVwUREAJIEW6Ih1pISR0EkKSSTJznz8GBsaEEGCSm/J9v17z0nvm3Jnf3N1n833OPfccwzRNExEREZEqwmZ1ASIiIiKBpHAjIiIiVYrCjYiIiFQpCjciIiJSpSjciIiISJWicCMiIiJVisKNiIiIVCkKNyIiIlKlKNyIiIhIlaJwIyIiIlWKpeHmhRdewDAMv1dcXFyJ58yfP5+OHTsSEhJCkyZNGDduXDlVKyIiIpWBw+oCEhMTmTt3ru/Ybreftu/27dvp27cvDz74IJMnT2bRokU88sgj1K1blwEDBpTq+zweD3v27CEiIgLDMM67fhERESl7pmly9OhR6tWrh81W8tiM5eHG4XCccbTmhHHjxtGgQQNGjx4NQMuWLVmxYgVvvfVWqcPNnj17SEhIONdyRURExEKpqanUr1+/xD6Wh5stW7ZQr149nE4nnTt35rXXXqNJkybF9l2yZAm9evXya7v22muZMGECBQUFBAUFFTnH5XLhcrl8xyc2QU9NTSUyMjKAv0RERETKSlZWFgkJCURERJyxr6XhpnPnzkyaNImLLrqIvXv38sorr9C1a1fWrVtHdHR0kf4ZGRnExsb6tcXGxlJYWMiBAweIj48vck5ycjIvvvhikfbIyEiFGxERkUqmNFNKLJ1Q3KdPHwYMGECbNm24+uqrmTFjBgAfffTRac/5/Y86MRJzuh87atQoMjMzfa/U1NQAVS8iIiIVkeW3pU4VHh5OmzZt2LJlS7Hvx8XFkZGR4de2b98+HA5HsSM9AE6nE6fTGfBaRUREpGKqUOvcuFwuNmzYUOztJYCkpCTmzJnj1zZ79mw6depU7HwbERERqX4sDTcjR45k/vz5bN++nZ9++olbbrmFrKwsBg0aBHhvKd17772+/oMHD2bnzp2MGDGCDRs28MEHHzBhwgRGjhxp1U8QERGRCsbS21K7d+/mzjvv5MCBA9StW5cuXbqwdOlSGjZsCEB6ejq7du3y9W/cuDEzZ87kT3/6E++++y716tVjzJgxpX4MXERERKo+wzwxI7eayMrKIioqiszMTD0tJSIiUkmczd/vCjXnRkREROR8KdyIiIhIlaJwIyIiIlWKwo2IiIhUKQo3IiIiUqUo3IiIiEiVUqG2X6jM3B6T9MxcAOrXCrO4GhERkepL4SZADma76PbGPGwGbEvuZ3U5IiIi1ZZuSwVYtVoRUUREpAJSuAkUw/uP6rXes4iISMWjcBMgxol0IyIiIpZSuAkQQ9lGRESkQlC4KQPVbC9SERGRCkXhJkBOHbhRthEREbGOwk2AGKfcl1K2ERERsY7CTYBoyo2IiEjFoHATIKdOKNacGxEREeso3JQBRRsRERHrKNwEyKnr3GjgRkRExDoKN4Fy6m0pjd2IiIhYRuEmQLSIn4iISMWgcFMGdFtKRETEOgo3AaKBGxERkYpB4SZA/Bbx08iNiIiIZRRuAkQjNyIiIhWDwk0Z0NNSIiIi1lG4CRD/FYqtq0NERKS6U7gJEL9F/CysQ0REpLpTuAkQrXMjIiJSMSjclAFtnCkiImIdhZsyoGgjIiJinQoTbpKTkzEMg+HDh5+2T0pKCoZhFHlt3Lix/Ao9DU0oFhERqRgcVhcAsHz5csaPH0/btm1L1X/Tpk1ERkb6juvWrVtWpZWaoZVuREREKgTLR26ys7MZOHAg77//PrVq1SrVOTExMcTFxfledru9jKs8M78JxRq5ERERsYzl4WbIkCH069ePq6++utTntG/fnvj4eHr27Mm8efNK7OtyucjKyvJ7lTUt4iciImIdS29LTZkyhVWrVrF8+fJS9Y+Pj2f8+PF07NgRl8vFf/7zH3r27ElKSgpXXHFFseckJyfz4osvBrLsYvkN3CjbiIiIWMaycJOamspjjz3G7NmzCQkJKdU5zZs3p3nz5r7jpKQkUlNTeeutt04bbkaNGsWIESN8x1lZWSQkJJxf8cUwtNCNiIhIhWDZbamVK1eyb98+OnbsiMPhwOFwMH/+fMaMGYPD4cDtdpfqc7p06cKWLVtO+77T6SQyMtLvVRY05UZERKRisGzkpmfPnqxdu9av7f7776dFixY8+eSTpZ4kvHr1auLj48uixHOmRfxERESsY1m4iYiIoHXr1n5t4eHhREdH+9pHjRpFWloakyZNAmD06NE0atSIxMRE8vPzmTx5MlOnTmXq1KnlXv/v+a1zY10ZIiIi1V6FWOfmdNLT09m1a5fvOD8/n5EjR5KWlkZoaCiJiYnMmDGDvn37Wlil16lzbjRwIyIiYh3DrGb3ULKysoiKiiIzMzPg828aPTUDgOXPXE3dCGdAP1tERKQ6O5u/35avc1OVnBi80To3IiIi1lG4KQvKNiIiIpZRuAmgE7NulG1ERESso3ATQFrIT0RExHoKNwHkG7nR0I2IiIhlFG7KgCYUi4iIWEfhJoB8T0sp24iIiFhG4SaADDTnRkRExGoKN4HkW+dGRERErKJwUwaq2aLPIiIiFYrCTQDpaSkRERHrKdwEkJa5ERERsZ7CTQBpQrGIiIj1FG4CSI+Ci4iIWE/hpgxoET8RERHrKNwEkCYUi4iIWE/hJoC0caaIiIj1FG4CyDdyY2kVIiIi1ZvCTRnQIn4iIiLWUbgJJG2/ICIiYjmFmwDSjBsRERHrKdwE0IkJxborJSIiYh2FmzKhdCMiImIVhZsA0grFIiIi1lO4CSDNuREREbGewk0A+ebcWFyHiIhIdaZwE0DafkFERMR6CjdlQBtnioiIWEfhJoC0tZSIiIj1FG4CSuvciIiIWE3hJoD0KLiIiIj1Kky4SU5OxjAMhg8fXmK/+fPn07FjR0JCQmjSpAnjxo0rnwLPgubciIiIWKdChJvly5czfvx42rZtW2K/7du307dvXy6//HJWr17N008/zaOPPsrUqVPLqdKS6WkpERER61kebrKzsxk4cCDvv/8+tWrVKrHvuHHjaNCgAaNHj6Zly5b84Q9/4IEHHuCtt94qp2pLpgnFIiIi1rM83AwZMoR+/fpx9dVXn7HvkiVL6NWrl1/btddey4oVKygoKCj2HJfLRVZWlt+rrBhao1hERMRyloabKVOmsGrVKpKTk0vVPyMjg9jYWL+22NhYCgsLOXDgQLHnJCcnExUV5XslJCScd91nottSIiIi1rEs3KSmpvLYY48xefJkQkJCSn2e8bt7P+bxJPH79hNGjRpFZmam75WamnruRZ+xtuM1aUKxiIiIZRxWffHKlSvZt28fHTt29LW53W4WLFjAO++8g8vlwm63+50TFxdHRkaGX9u+fftwOBxER0cX+z1OpxOn0xn4H1AM3ZQSERGxnmXhpmfPnqxdu9av7f7776dFixY8+eSTRYINQFJSEl9//bVf2+zZs+nUqRNBQUFlWm9p+DbO1MCNiIiIZSwLNxEREbRu3dqvLTw8nOjoaF/7qFGjSEtLY9KkSQAMHjyYd955hxEjRvDggw+yZMkSJkyYwKefflru9ZdE2UZERMQ6lj8tVZL09HR27drlO27cuDEzZ84kJSWFiy++mJdffpkxY8YwYMAAC6ssytTQjYiIiGUsG7kpTkpKit/xhx9+WKTPlVdeyapVq8qnoLOkdW5ERESsV6FHbiqbk09LiYiIiFUUbgLI0K7gIiIillO4KRNKNyIiIlZRuAkgzbkRERGxnsJNAGlXcBEREesp3ASQbxE/i+sQERGpzhRuyoBGbkRERKyjcBNAmnIjIiJiPYWbQDqxzo2GbkRERCyjcBNAvgnFllYhIiJSvSncBJB2BRcREbGewk0ZMDV2IyIiYhmFmwDShGIRERHrKdwEkKFJNyIiIpZTuAkg38aZFtchIiJSnSnclAFNKBYREbGOwk0AaeNMERER6ynclAE9LSUiImIdhZsA0jo3IiIi1lO4KQPKNiIiItZRuAkgTbkRERGxnsJNABnaOFNERMRyCjcB5As31pYhIiJSrSncBNCJRfyUbkRERKyjcCMiIiJVisJNAJ28LaWhGxEREaso3ASQb99MZRsRERHLKNwEkhbxExERsZzCTRlQthEREbGOwk0AaRE/ERER6yncBJAW8RMREbGepeFm7NixtG3blsjISCIjI0lKSuLbb789bf+UlBQMwyjy2rhxYzlWfXq+CcWWViEiIlK9Oaz88vr16/P666/TtGlTAD766CNuvPFGVq9eTWJi4mnP27RpE5GRkb7junXrlnmtpaFdwUVERKxnabi5/vrr/Y5fffVVxo4dy9KlS0sMNzExMdSsWbOMqxMREZHKqMLMuXG73UyZMoVjx46RlJRUYt/27dsTHx9Pz549mTdvXol9XS4XWVlZfq+ycnJCsYZuRERErGJ5uFm7di01atTA6XQyePBgpk2bRqtWrYrtGx8fz/jx45k6dSpffvklzZs3p2fPnixYsOC0n5+cnExUVJTvlZCQUFY/5ZQJxWX2FSIiInIGhmnxoz35+fns2rWLI0eOMHXqVP79738zf/780wac37v++usxDIPp06cX+77L5cLlcvmOs7KySEhIIDMz02/eTiDcNm4Jy3Yc4l8DO9C3TXxAP1tERKQ6y8rKIioqqlR/vy2dcwMQHBzsm1DcqVMnli9fzj/+8Q/ee++9Up3fpUsXJk+efNr3nU4nTqczILWKiIhIxWf5banfM03Tb6TlTFavXk18fAUZJdFtKREREctZOnLz9NNP06dPHxISEjh69ChTpkwhJSWFWbNmATBq1CjS0tKYNGkSAKNHj6ZRo0YkJiaSn5/P5MmTmTp1KlOnTrXyZ/icXOdG6UZERMQqloabvXv3cs8995Cenk5UVBRt27Zl1qxZXHPNNQCkp6eza9cuX//8/HxGjhxJWloaoaGhJCYmMmPGDPr27WvVT/CjCcUiIiLWs3xCcXk7mwlJZ+uO8UtYuu0Q/7yzPde3qxfQzxYREanOzubvd4Wbc1OZGcdvTFWrtCgiIlLBKNwEkDbOFBERsZ7CTQAZxpn7iIiISNlSuAkgA6UbERERqynclAHdlRIREbGOwk0A+ebcaEqxiIiIZRRuyoBGbkRERKyjcBNAxvGhG4UbERER6yjciIiISJWicBNAJ/eWEhEREaso3ASQFvETERGxnsJNAGnkRkRExHoKNyIiIlKlKNwEkHFyoRsRERGxiMJNAJ28LaV0IyIiYhWFmwA6OaHY2jpERESqM4WbgNLGmSIiIlZTuCkDGrgRERGxjsJNAOm2lIiIiPUUbgJIE4pFRESsp3ATQIam3IiIiFhO4aYM6LaUiIiIdRRuAsg4fmNK2UZERMQ6CjcB5LstpaEbERERyyjcBJB2XxAREbGewo2IiIhUKQo3AeSbc6OhGxEREcso3ASSbxE/pRsRERGrKNwE0MlF/ERERMQqCjcBZGgVPxEREcsp3JQB3ZUSERGxjqXhZuzYsbRt25bIyEgiIyNJSkri22+/LfGc+fPn07FjR0JCQmjSpAnjxo0rp2rPTLelRERErGdpuKlfvz6vv/46K1asYMWKFVx11VXceOONrFu3rtj+27dvp2/fvlx++eWsXr2ap59+mkcffZSpU6eWc+XFMzShWERExHIOK7/8+uuv9zt+9dVXGTt2LEuXLiUxMbFI/3HjxtGgQQNGjx4NQMuWLVmxYgVvvfUWAwYMKI+SS2Qz9Ci4iIiI1SrMnBu3282UKVM4duwYSUlJxfZZsmQJvXr18mu79tprWbFiBQUFBcWe43K5yMrK8nuVFbvNG27cSjciIiKWsTzcrF27lho1auB0Ohk8eDDTpk2jVatWxfbNyMggNjbWry02NpbCwkIOHDhQ7DnJyclERUX5XgkJCQH/DSfYj4/cuD0KNyIiIlaxPNw0b96cNWvWsHTpUh5++GEGDRrE+vXrT9v/949bn5jfcrrHsEeNGkVmZqbvlZqaGrjif8dmU7gRERGxmqVzbgCCg4Np2rQpAJ06dWL58uX84x//4L333ivSNy4ujoyMDL+2ffv24XA4iI6OLvbznU4nTqcz8IUXw348KirciIiIWOecRm5SU1PZvXu373jZsmUMHz6c8ePHn3dBpmnicrmKfS8pKYk5c+b4tc2ePZtOnToRFBR03t99vhw27+X0aM6NiIiIZc4p3Nx1113MmzcP8M6Dueaaa1i2bBlPP/00L730Uqk/5+mnn2bhwoXs2LGDtWvX8swzz5CSksLAgQMB7y2le++919d/8ODB7Ny5kxEjRrBhwwY++OADJkyYwMiRI8/lZwTciaelCjVyIyIiYplzCje//vorl156KQCff/45rVu3ZvHixXzyySd8+OGHpf6cvXv3cs8999C8eXN69uzJTz/9xKxZs7jmmmsASE9PZ9euXb7+jRs3ZubMmaSkpHDxxRfz8ssvM2bMmArxGDicvC3lUbgRERGxzDnNuSkoKPDNY5k7dy433HADAC1atCA9Pb3UnzNhwoQS3y8uKF155ZWsWrWq9MWWI00oFhERsd45jdwkJiYybtw4Fi5cyJw5c+jduzcAe/bsOe3E3urAoXVuRERELHdO4eaNN97gvffeo3v37tx55520a9cOgOnTp/tuV1VHWudGRETEeud0W6p79+4cOHCArKwsatWq5Wt/6KGHCAsLC1hxlY1uS4mIiFjvnEZucnNzcblcvmCzc+dORo8ezaZNm4iJiQlogZXJiZEbPQouIiJinXMKNzfeeCOTJk0C4MiRI3Tu3Jm//e1v9O/fn7Fjxwa0wMrEbj/+KLhb4UZERMQq5xRuVq1axeWXXw7Af//7X2JjY9m5cyeTJk1izJgxAS2wMvHNudHIjYiIiGXOKdzk5OQQEREBeFcIvvnmm7HZbHTp0oWdO3cGtMBKI/cw7XZ/zFOOT7TOjYiIiIXOKdw0bdqUr776itTUVL777jt69eoFePd5ioyMDGiBlUZmGl22/I3/s39LaMFhq6sRERGpts4p3Dz33HOMHDmSRo0acemll5KUlAR4R3Hat28f0AIrjbjWHIhMJMhw0/roQqurERERqbbO6VHwW265hW7dupGenu5b4wagZ8+e3HTTTQErrrI5FNWKOlnriCw4YHUpIiIi1dY5hRuAuLg44uLi2L17N4ZhcMEFF1TrBfwACoJrAhDmPmptISIiItXYOd2W8ng8vPTSS0RFRdGwYUMaNGhAzZo1efnll/F4PIGusdIoCI4CIFThRkRExDLnNHLzzDPPMGHCBF5//XUuu+wyTNNk0aJFvPDCC+Tl5fHqq68Gus5KofB4uAlzZ1lciYiISPV1TuHmo48+4t///rdvN3CAdu3accEFF/DII49U23DjdnrDTbhHIzciIiJWOafbUocOHaJFixZF2lu0aMGhQ4fOu6jKqsBZE4Bw3ZYSERGxzDmFm3bt2vHOO+8UaX/nnXdo27bteRdVWXlOhBtT4UZERMQq53Rb6q9//Sv9+vVj7ty5JCUlYRgGixcvJjU1lZkzZwa6xkrDfTzc1PAcBdOE49sxiIiISPk5p5GbK6+8ks2bN3PTTTdx5MgRDh06xM0338y6deuYOHFioGusNE6M3NjxgEujNyIiIlYwTDNwuzz+/PPPdOjQAbfbHaiPDLisrCyioqLIzMwM+FYRP2zcS9dPEwkxCuCxX6BWw4B+voiISHV1Nn+/z2nkRopnt9k4Qg3vQa72lxIREbGCwk0A2Q2DTDPce5B3xNJaREREqiuFmwCy2dDIjYiIiMXO6mmpm2++ucT3jxw5cj61VHoOm41jptN7kJ9jbTEiIiLV1FmFm6ioqDO+f++9955XQZWZ3QZ5BHsPChRuRERErHBW4aY6P+ZdGjbDIJfjIzeFedYWIyIiUk1pzk0A2W0GeeaJkZtca4sRERGpphRuAijYYTvltpTCjYiIiBUUbgIoNMhOrsKNiIiIpRRuAig0yE7u8aelTE0oFhERsYTCTQCFBJ8cufHka+RGRETECgo3ARQaZMflCzcauREREbGCpeEmOTmZSy65hIiICGJiYujfvz+bNm0q8ZyUlBQMwyjy2rhxYzlVfXpBdhsuw3tbSuFGRETEGpaGm/nz5zNkyBCWLl3KnDlzKCwspFevXhw7duyM527atIn09HTfq1mzZuVQ8Zl5HKHef+q2lIiIiCXOahG/QJs1a5bf8cSJE4mJiWHlypVcccUVJZ4bExNDzZo1y7C6c+Oxh4IbKDhzQBMREZHAq1BzbjIzMwGoXbv2Gfu2b9+e+Ph4evbsybx588q6tFLLD4oAwMjLtLgSERGR6snSkZtTmabJiBEj6NatG61btz5tv/j4eMaPH0/Hjh1xuVz85z//oWfPnqSkpBQ72uNyuXC5XL7jrKysMqnf931BUZAHDpd2BRcREbFChQk3Q4cO5ZdffuHHH38ssV/z5s1p3ry57zgpKYnU1FTeeuutYsNNcnIyL774YsDrPZ384FoAOPKzwF0I9gpziUVERKqFCnFbatiwYUyfPp158+ZRv379sz6/S5cubNmypdj3Ro0aRWZmpu+Vmpp6vuWWyB18ys7puRq9ERERKW+WDiuYpsmwYcOYNm0aKSkpNG7c+Jw+Z/Xq1cTHxxf7ntPpxOl0nk+ZZ8XpDCbTDCPKyIHcQ1Cjbrl9t4iIiFgcboYMGcInn3zC//73PyIiIsjIyAAgKiqK0FDvI9WjRo0iLS2NSZMmATB69GgaNWpEYmIi+fn5TJ48malTpzJ16lTLfsepQoPsHDYjvOEm55DV5YiIiFQ7loabsWPHAtC9e3e/9okTJ3LfffcBkJ6ezq5du3zv5efnM3LkSNLS0ggNDSUxMZEZM2bQt2/f8iq7RCFBdo7iDWa4jlpbjIiISDVk+W2pM/nwww/9jp944gmeeOKJMqro/IUG2zh2ItzkK9yIiIiUtwoxobgqCQ2yk22GeA9c2dYWIyIiUg0p3ARYaJD9lJEbhRsREZHypnATYCHBdo5p5EZERMQyCjcBFhZkJ1tzbkRERCyjcBNgoRq5ERERsZTCTYCFBNnJ5ni40ZwbERGRcqdwE2B+E4q1zo2IiEi5U7gJsPioUN9tKVPhRkREpNwp3ARYs9ga5BjekZvCXIUbERGR8qZwE2AhQXYiImsB4MlKt7gaERGR6kfhpgxE164NgDNvP/w03uJqREREqheFmzJQNzr65MG3j1tXiIiISDWkcFMG6tapY3UJIiIi1ZbCTRlwhkVaXYKIiEi1pXBTBpyhNawuQUREpNpSuCkDocGOkwf2YOsKERERqYYUbspAaLCNpwv+z3sQWc/aYkRERKoZhZsyEBJkZ6Wnmfcg/5i1xYiIiFQzCjdlICzYwbHjm2fm52rzTBERkfKkcFMGQoPs5BzfXyrYk8uh7DyLKxIREak+FG7KgHdn8BDfcWbmYQurERERqV4UbspAaLAdF8HkmE4Asg9lWFyRiIhI9aFwUwaC7AYAB0zvYn6OHQusLEdERKRaUbgpA4bhDTeRRg4ALVc+Z2U5IiIi1YrCTRn5553tqWmc8hh4Yb51xYiIiFQjCjdl5Pp29TgSHHeyIVeTikVERMqDwk0ZWtVlzMmD/z0CpmldMSIiItWEwk0Zqtcq6eTB1rkw48/WFSMiIlJNKNyUoZiIEP+GFROsKURERKQaUbgpQ5EhjjN3EhERkYBSuClDDruNP3pGWV2GiIhItaJwU8bWhl7CJk99q8sQERGpNiwNN8nJyVxyySVEREQQExND//792bRp0xnPmz9/Ph07diQkJIQmTZowbty4cqj23ESGBvGngkcAyHPWsbgaERGRqs/ScDN//nyGDBnC0qVLmTNnDoWFhfTq1Ytjx46d9pzt27fTt29fLr/8clavXs3TTz/No48+ytSpU8ux8tKLDA0iF+8eU2aBdgcXEREpa5bOeJ01a5bf8cSJE4mJiWHlypVcccUVxZ4zbtw4GjRowOjRowFo2bIlK1as4K233mLAgAFlXfJZczpsuMwgAIJMrVIsIiJS1irUnJvMzEwAateufdo+S5YsoVevXn5t1157LStWrKCgoKBIf5fLRVZWlt+rPF1YtwYuvOHGYebDvg3l+v0iIiLVTYUJN6ZpMmLECLp160br1q1P2y8jI4PY2Fi/ttjYWAoLCzlw4ECR/snJyURFRfleCQkJAa+9JMOuauoLNwD8q0u5fr+IiEh1U2HCzdChQ/nll1/49NNPz9j3xK7bJ5jHtzX4fTvAqFGjyMzM9L1SU1MDU3ApRddw8re7LvVr233gSLnWICIiUp1UiHAzbNgwpk+fzrx586hfv+THpuPi4sjIyPBr27dvHw6Hg+jo6CL9nU4nkZGRfq/ydmFsLb/jd/8zpdxrEBERqS4sDTemaTJ06FC+/PJLfvjhBxo3bnzGc5KSkpgzZ45f2+zZs+nUqRNBQUGnOctajerU8DuOPfiTRZWIiIhUfZaGmyFDhjB58mQ++eQTIiIiyMjIICMjg9zcXF+fUaNGce+99/qOBw8ezM6dOxkxYgQbNmzggw8+YMKECYwcOdKKn1AqDrv/ZW5q7LGoEhERkarP0nAzduxYMjMz6d69O/Hx8b7XZ5995uuTnp7Orl27fMeNGzdm5syZpKSkcPHFF/Pyyy8zZsyYCvkY+Ok0NPZaXYKIiEiVZZgnZuNWE1lZWURFRZGZmVm+82/eToSs3SeP//A91O9Uft8vIiJSiZ3N3+8KMaG4WhiylGW9Z5w8/ndPOLzDsnJERESqKoWb8uKMILxBG/+2rd9bU4uIiEgVpnBTjiKc/k9zrVq3gWp2V1BERKTMKdyUo6hQ/3CzeesWvlyVZlE1IiIiVZPCTTmKCvMPN3c4UkhZvc6iakRERKomhZvydu90v8MmWSshPwcKtWO4iIhIIOhRcCt43PDS73Y+r9sChmjlYhERkeLoUfCKzmbnQNNb/Nv2b/SO4IiIiMh5UbixiBFWdJNPcg6WfyEiIiJVjMKNRezhRcPNht+2W1CJiIhI1aJwYxF7RJ0iba9P/dGCSkRERKoWhRuL2Ftcy0pPM7+2+sZ+8grcFlUkIiJSNSjcWCSk5gUMyH+RRe5EX9st9gVs3ZfNjF/SOZpXYGF1IiIilZfCjUVsNgOARwoeY0phdwBaGTu57p8LGfLJKl75ZoOF1YmIiFReCjcWy6QGzxY+gMc0cBoFRJMFwGcrUi2uTEREpHJSuLHQrOGX89AVTSjAwT5qAjDAvgCAJnXDLaxMRESk8lK4sVCLuEiuaxsPwB7T+2j400Gf0sO2mvrOPNi/ycryREREKiWH1QVUdwbeuTcZ5sntGCYGvwkHgHeBu7+Epj1JnrmBsGAHj13drPgPEhEREUAjN5ZrFluDiBAH68IuLfZ917ZF/LY/m/cWbOPvczeTX+gp5wpFREQqF43cWCwkyM6yp6/GbvSEH4Al7/i971z8N3Y3HOw7znYVUtsRXM5VioiIVB4auakAQoPtBAc54JqXin1//Ecf+P5d69+IiIiUTOGmIrHZIaRmkeaPg5NZ77yfBsZedhzUzuEiIiIlUbipaB5KIb/lAHq7Xvct7gcQZrj4OOg1Bn2wzLraREREKgGFm4qmdmOCb/+A5/5wK0cJ83srwbafMPIsKkxERKRyULipoLpeWIcJ7n5F2teHPEDBYa1eLCIicjoKNxXYQVttuuaNKdK+c9Y/Sc/MJfWQ5t+IiIj8nh4Fr8BCHHYOuiOLtDfd9B6PrnUw3XMZlzauzZUX1WVIj6YWVCgiIlLxaOSmAouJdOIimNnujrjj2rHVU8/33pjgd6lFFsu2H+LN77zbNKzceZg1qUcsqlZERKRiULipwBpGezfPfKjgz9j/OJ+ZHv9VjGc5n8JJPgDfrctgwNjFDHx/Ka5Ct6/P1n3ZJH+7gUPH8suvcBEREQsp3FRgz13Xitrhwfz5movAMMgy/XcKjzWOkGjsAODvczYDcCzf7Rdkbh23mPfmb+OZaWvLrW4RERErac5NBdaoTjgr/3I1huHdXPMYIUX6fOl8gUZ5H7Mx46iv7fCxAuIiQzAMg8M53hWNF209UD5Fi4iIWMzSkZsFCxZw/fXXU69ePQzD4Kuvviqxf0pKCoZhFHlt3LixfAq2wIlgAzC0S3SxfXrY1vgdv79wG4nPf8dbx+fiABS4zTKpT0REpKKxdOTm2LFjtGvXjvvvv58BAwaU+rxNmzYRGXnyKaK6deuWRXkVzgXtroaVfy3SPjH4TX7ytOCjwl7kEczFayey253EO/NOzr0pcGs3cRERqR4sDTd9+vShT58+Z31eTEwMNWvWDHxBFV2DzhTe+w3bfprBRZvG+r3V2baRzsEnR7AGOebQKO8T33Ghx+TbtemkHs7hwcub+I0IiYiIVCWVckJx+/btiY+Pp2fPnsybN6/Evi6Xi6ysLL9XZeZocjkX3fk6dzreZrWnKZ94riG/lBn14Y9X8drMjSzYovk3IiJSdVWqcBMfH8/48eOZOnUqX375Jc2bN6dnz54sWLDgtOckJycTFRXleyUkJJRjxWXn+T/cyr+bv8+lQz/k4K1fFdvHwENHYxPvBb1NfWO/r/2Tn3ay50huOVUqIiJSvgzTNCvETFPDMJg2bRr9+/c/q/Ouv/56DMNg+vTpxb7vcrlwuVy+46ysLBISEsjMzPSbt1OpZe6GvycWad7iuYBmtjQAlnpackf+s37vb0/ue/JJLFchwQ4bQfZKlXdFRKSayMrKIioqqlR/vyv9X7IuXbqwZcuW077vdDqJjIz0e1U5NWKLbT4RbADfejineuTjVQBk5hRw6atzGfj+T2VSnoiISHmq9OFm9erVxMfHW12GtexB0PjKErtEGLncZFtIc2OXL+h8+2sGv6ZlkrJ5H8fy3SzbcQjTNKkgg3kiIiLnxNKnpbKzs9m6davvePv27axZs4batWvToEEDRo0aRVpaGpMmTQJg9OjRNGrUiMTERPLz85k8eTJTp05l6tSpVv2EiuOeryA/G9Z+DjP+XGyXvweffMIqMW8Cxwhl6baDhATZfe1Ltx3ioUkreKJPC+7p0rCsqxYREQk4S8PNihUr6NGjh+94xIgRAAwaNIgPP/yQ9PR0du3a5Xs/Pz+fkSNHkpaWRmhoKImJicyYMYO+ffuWe+0Vjs0GIZFwyR/AEQK/TvX+c9PMYrsPsC/gFvsC1q65jmfSknztf5+7maOuQp796lc6NqhFXFQItcODATBNE8MwyCtwk5VbQExk0RWTRURErFZhJhSXl7OZkFTp7VkDMx+H2Faw8sNiuxSaNpq6/kMsh8klmGYNE1i587Bfn3/ccTE2w+DPX/zMe/d05K+zNrEhPYvFT11FvZqhZf87RESk2jubv98KN9VFYT6MTYKDW4u8tdrTlPa2rfzqacSzQX/m+YLRjC68mRRP+xI/8tWbWjOwc0PcHhO7TYsCiohI2alWT0tJKTmCYegKGDChyFvtbd7A09q2g2nuYVxs+40Pg9+kLoeL9D3VMVch6/dk0emVOdp1XEREKgyN3FRHk2+BrXNK1bWn601+My/gKpv3sfEfPB1O2/eJ3s3Jyi3kqT4tAlKmiIjICWfz99vSCcVikdYDfOHmh9q3cdWhz0/b9Xvn43xl70V/92wA7sx/hiWeogsGAvx1lncX8shQB03qhNM0pgZNYyICXLyIiEjJNHJTHZkmrJgAMa2gYVdv2w+v4ln4N8YU3Mhwx5clnv5w/mPM8lyCHQ+FZ8jH3wzrRusLogJVuYiIVFOaUFwChZvTME3MglzmbMmifVwQdWcNhi2zSzxlt1mH2+3/IC3n9JOJeyfGUa9mKEN6XEh0DWegqxYRkWpC4aYECjdnYeMMmHJXiV2yG1/L0E3tSPG0A0p+YmpAh/rsPHiMf93dgVU7j9D6gkie+9867rgkgV6Jcew/6uK+icsY0KE+D3RrHMAfIiIilZ3CTQkUbs7S/Ddh3iul6rrPrEmMcYTtnlj+5b6Rr91JfBH8IjZMbsh/BTf2Ys+r4XTw64vX8qfP1jBttXc/rB2v9wvYTxARkcpPE4olcLoOg8I87yTkmgneW1X/faDYrjHGEQAa2/bypm08f7R/Q1PbHgAutW1khOMLPnd35wt3d7/zcgvcHD6W7ws2AMt3HGJflotJS3bw9u0XUy8qBMMw+DUtk5phQdSvFVYmP1dERCo/jdzI2Zv+KKz6yPvvPf5SqpEdl+nAaRQC0CjvE7/36nKE/URR0m2t0CA7w3o29T2Rte21vth+t3CgaZoUekyC7Fq+SUSkqtEiflK2rvs73P0lPLULrnwc2t5+xlNOBBuASUHJLHEO5arQrfS2LWN5yCMMsf+vxPNzC9y+YAOwPj2ryO7ld73/E93fTCGvwF2qn/G/NWncP3EZmbkFpeovIiKVg8KNnD2bHZr2hJDjj3hf9RffW+adn0HH+0o8/Qr7WuKNQ3xgPse44NEAPB70OW2N33jS8SlNjD1nLOG6f/5Ij7dSyMn3hqb9R10s2XaQtCO5bNmb7a3FNNlx4BhuT/GDk49NWcO8Tfv55/dbzvh9IiJSeWjOjZy/mg3ghUzg+I2lC3t45+gs/BvEJMLSd0v1MdOdzwJwvX0JHxT2Ya6nA/mmg0NEkk8QlxgbGRX0CRMK+zLD04UdB3No9dx3zB1xBX+fczKg5BW62ZuVx9uzN/PZilQe6X4hT/Q+/arJOw/lnPNPFxGRikdzbqRsFbpg8gDYsfCcP2KNpwm35T/P5pBBvrZnCh6gs20D/y7syy/mhX79/zWwA/9euI1Vu4742sbd3YHereP9+jV6aobv3/86oC23dqqPYWgDUBGRikiPgpdA4cYirmzI3A2eQhh3mbeteT/YNKPk847b4YmlkW1v0Y81HTR3TaImR6ltHGWbWa/EzxnS40Iev7YFs35NZ/DkVX7vfXBfJ65qEes79nhMXvpmPc3jIrjjkgQFHxERC+lRcKl4nDUg5vitoTungD0Ymvbk501byd71M5dteNU7MfnAJvh1apHTiws24J2oHMNhloUMAeAP+X+mvrGfA2YU33kuoQAHYHK/fRZ5BLNm/louWdGJ/UddRT7rgQ9X8OmDXWgVH0lUWBCz1+/lw8U7AFiblsmr/Vsr4IiIVAIauZGKxeOBw9sxJ/bFyM4IyEf+peB+Xgma6Du+1fUctztSSDdr87fC24r0d9gMZv/pCn7YuI9XZmzwtTeNqcH0oZcRbLdhM4wij6KfcPhYPjbDICosKCD1i4iIbkuVSOGmksjLgqMZ3iezoi+Ewzs5vOxTchNvZ9u6FXRb8odz/uhcM5hQIx+Atnnvk0U4Njy87JjIVrMeE919AKhfK5Tdh3P9zn382ua8+d0mrm4Zwzt3dfAGHZvBhvQs1qQeoW+beHr+LQWnw873f76SnHw3tcKCtP6OiMh5UrgpgcJNFbFqEmz4BhpfQX7eMVb/sobOR2ay1xZDREgwYTm7S/Ux37ovYWTBYLrZ1vLe8cfS+7teYo3ZtNj+NjyYgHnKKgqtL4jk17QsAOKjQkjPzDvZ34CIkCBiI50MvvJCvt+4j+Sb27DrYA6t4iNPO/pTHNM0ST2US0LtUN0eE5FqR+GmBAo3VVh+DgQf35YhMw1WToSsdMj4GfZtoOCSPxL0U+keS//Z04TnC+5jjxlNtJHFTjOWy21reS/47/zkacHt+c+dc5lhwXZy8k8uNPjZQ13o3CTar88xVyF5BW6/ndT/s2QHz/5vHc9e14r/08aiIlLNKNyUQOGmmvt6uDf0nKebXC+y2mwGQGdjAzfaF/F64Z1kEX5Onzdr+OXER4YS5DAIC3bQ6+/zSTucy+Knevrm7pz66PoTvZvz3a8Z/OcPnYkMKf3cnvxCD5m5BdSNcJ65s4hIBaJwUwKFGyH9Z9i7HlZ8ALuXeZ/cuvQhyN4Haz8/748fkT+YmZ7OFGKn8CwfSGwUHca/B13C1W/PB7yTmOvWcPLWbe247PUfivT/S7+W/OHyJhzNKyA0yI7jDPN67np/KYt/O8iCx3vQIFqbj4pI5aFwUwKFG/HJOQSHtkH9Tifbpj8Kaz6GTg9ATCv4Zvg5f/wSdys+dveksZHOXc4fSc67hQ62zSTZ1vNUwYOsNpsRyyGyCCMXJyVtHHo6/9etMYOSGtH7HwuoFRbMjRfX4+YO9WkaU4N/fr+FGWvTmfR/lxITEYLHY9Lk6ZkA/PmaixjWs5nvc/ILPazceZgODWvidNjP+TeLiJQVhZsSKNxIiUzTu9Cg/fitnl1LwRlB/oHtpH02gpcL7+Efw24jYnI/OLY/oF9daNp4s/B2prh7kEkNbrWn4DZt/OBpTw4h5FO62089mtdlwqBLfEHm/7o15tnrWrH7cA7d3pgHwDWtYtm6L5tLG9XmjVva8trMDYxfsI17kxry0o2tz6puj8fkxa/X0SI+kjsvbXBW54qIlJbCTQkUbuRcLdt+CI9p0uXE5N/U5bDhf7BnjXen9OimsGUOfHLreX+Xy3T47aSebtZmnvtiPnFfxa9mEww8pzyxZRKEmwIcOMmnu20NqbWSWH/QO2m5W9M6vHZTG654c16x33V5szos3HLAd9ypYS06NqrFyF7NcdgMjuW7qeE8/e21L1ftZsTnPwOw4/V+fu+ZpkmB2yTYYSvSrie+RORsKNyUQOFGypQrG/7ZEXIOku8IJ9tVyMbIbnS99FL4/qWT/S6+G9ZMPqevKDCCCTLzyTLD8GAQTh5Bhpv1noa0su0EvE97DSl4jN1mXQAMPMRxmHSicVBIIXbOdBusSZ1wQoLsbNp7lL/d2o4rL6pLrfBgvz5ZeQW0fWG27/i31/piP+Xx9hGfreH7jfuYO+JK3yTmT37axfPTf+XlG1tzh0Z6RKSUFG5KoHAjZa7Au/Cf6Qjht/3HaFA7zDtysXc9bJ8P7e8GZwSkvAEpr5VpKT/Rmo2F8dxl/4Egw81U9+XcaFvEFrM+tYyjPFnwEDfYFzHT3ZnvPR2pRRYugnnUMY1MM5wNZgIpnvaAd+XmZ69rxdRVu3nxhkQMw6D/u4v8vu+1m9oQ7rQTFRpE+wa1aPfiyeDzf90a06FBLYZ8cnJPr9+P9IiInI7CTQkUbqTCycuCDV9D8z7eFZlfPzmacUvEx/z36MCTfcPrQv4xKMgpt/J6uP7GbrPu8X26zo/dZuD2nPyfnN9e68s7P2wlPiqEGy6uR0hQ0cnMbo/JkZx8QoPthAVrOzyR6krhpgQKN1Lh5RzyvuocXyV57zrYvRw6DALD8E56Xv8VhMfA14/BwS0AeJr3w9bqBjiwxfv+wa0BKynftPOx+2rWmw15M2g8i92teLLwQVLN2DOffJwND+HkcZSTj6A/07clr8707t/Vr0087w7s4P0tHhPDAMMwePO7jbw77zcAXroxkS5Nohk8eSV7M/N4uX9r/jZ7M6P6tqBfm/iAzeM5kO0iKjRIW2aIVCAKNyVQuJEqpSAPTDc4QrzHtlNGPlZNgq1z4YZ3ICSShT+mcPncG0/7UT+6E+lmX3dWXz+hsA9tbb9Rg1xmuLuwy4zhe08HLrFtZJGnDXU5wgXGAXaYsfzJMZU77PO4Jf95VpkXEUxBkSfA2tWP4ufdmQBcUDOU8fd2pN+YH0tdz8DODXj1pja+Xd9Ls1jhb/uzWbHjELd2TMBmM9i2P5tef1/AVS1iGH9vpzOeLyLlQ+GmBAo3Uq3tXQeHd3pvgX0zHFZ+CO3uwrzhn4ycuo4ETyp/jN9KwYr/EHl0K55ajVkZ3p1Ldp//qs6nyjJDiTRyebLgQWqQS3vbFn5wt6erfT2jCwccnwhtAgaRZFOAg1xCSvXZt3dK4LMVqYB3q4tn+rXko8U7GH71RfRtE8/BbBdvzNrIrZ0SaFe/Jhf95VsARt9+Mf3bX8AL09fx4eIdAGxP7ktmbgE/bj1At6Z1qBkWfLqvFZEyVmnCzYIFC3jzzTdZuXIl6enpTJs2jf79+5d4zvz58xkxYgTr1q2jXr16PPHEEwwePLjU36lwI1IKuYdh6VhoeztEX4i5fSGF2xayICueSy+6gIhd38NP48rs63d4Ygk38niq4A+8HTQWgKcKHmSQYzYtjZ0s9LTha3cSeTiZ72lX6s+9N6khk5bsPO37C5/owTs/bPWFo2mPdOWTn3bxxcrdNI+N4PUBbdhzJI8x32/hjVvacnFCzVJ/9+SlO7HbDK0FJHKOKk24+fbbb1m0aBEdOnRgwIABZww327dvp3Xr1jz44IP88Y9/ZNGiRTzyyCN8+umnDBgwoFTfqXAjEiCmCRlrwVkDsvfDui/hl88h91CRrnPcHbnGvrJMytjmiePm/BdpadtFP9tSvvNcwkJPW+pyhFeDJtDYyGCJpxUvFd5zxu0wEmqHUjss2Hdr7Ex9Fz5xFQBLtx3kjVkb6ds6ngevaOLXb/2eLDZmZPnWAlr97DV+j9Sv2HGIb35JZ+S1zUtcT+gEj8fEZjNwFbr9VpP+bX82NZwOYiNLN8IlUtlUmnBzKsMwzhhunnzySaZPn86GDRt8bYMHD+bnn39myZIlpfoehRuRMnQk1Rtu4tt5w8+6L5m2N4Zfc6P5S8cCjIxfoW4LiKoPmanwzZ8g45dyKW2xuxUmBmlmHW62L+QnT0tycJJceBfbzHrn9JkxEU6G9GjK3A17fQsh1o1w8uINifRtE8936zL443/8Q91z17XCBG5ufwHZrkIu/6t3ccVhVzXlz72aA95d4Z/73zrSM3NpW78mT/ZujmEYLN9xiAcmLscZZOPQsXwm/19nki6M5o7xS/lpuzdUnvp4vWmapB7KZfPeo/RsGaOFE6VSq7Lh5oorrqB9+/b84x//8LVNmzaN2267jZycHIKCii5P73K5cLlcvuOsrCwSEhIUbkQqiIKMDRQs/5Cw3Azo+Zx3DSCbw/vPVZMwf/kcI3Wpt/P/zYUJVwe8hpcL7uYHT3sG27+mg20LNjzM8XRiQmFvXARzl/17brAvYYGnLf8qvKFUu7/f0rE+/125u9Q19G0Tx78GduRoXgFtTlkY8YQpD3Vh6CerOJCd72trVz+Kdwd28G2rAbDx5d6EBNn5anUaL32znkPHvP1PbLL6e+v3ZFHD6SjVRqq/pmWyMeMoAzpcoKAk5a7KhpuLLrqI++67j6efftrXtnjxYi677DL27NlDfHx8kXNeeOEFXnzxxSLtCjcilciGr6HORVC3OezfBDkHISgUajaECb3AUwB/XEBe7jFca78i6odRHLPVIKXzv+nXJAg+vcPbJ8COmU4WexJpZqTRyLaXm10vkGrGcIgIutjW46SAfvaf2OWJYZ3ZiK1mPXaY8XQ2NvC34LEs87Tgw8JrqWHk8punHmZEPPuOuor9rqtaxPDDxn1F2utFhbAnM893nDKyO7GRIdwybjHr9mT52kOD7DzZuzmvztzAR/dfStemdfz2G3vgssZ8sGg7AGPubM8N7YqOZjV6agYAk/+vM92a1QHgh417WZeWxdCrmvoFHtM0eW3mBmIjQ4oNVSJnq0qHm/vvv59Ro0b52hYtWkS3bt1IT08nLi6uyDkauRGp4twFYNj8H4PP3O1tizz+B3rHIvjlM0hbCZ0eYPTMlQw3P8Y07BimB++TWeXjs8Lu3O5IKdK+wZPA9fmvcrGxlZ/NphRgp5mRRltjG21s25jluZRdnhgKsbOPWgA4yacWR7HjwTBMdpsxAESEOMgv9OAq9Jy2jpG9LmLK8lR2H84t9v3tyX0xDIOsvAJqBDvId3to8ewswDsK1K9tPEt+O+ibS/Tpg11IujDad/76PVn0HbMQgE2v9C6y2/zGjCxem7mRwVc0oWvTOqW8elKdnU24qVTLfcbFxZGRkeHXtm/fPhwOB9HR0cWe43Q6cTrPvNaFiFRS9mJ2S4+q73/c6DLv67j7W93D3t33EtvsEm8oSnkDFr4FXYdBfg5smA5ZaUU+dkfNLjQ6shRsQdDmVvj5k7Mut7hgA9DSlsrWkHtPe959+N+qKjDtBBluv7a/FtzGOrMx21xx7DbrEkUOLoLIw4kdb1833pDx1uzNvvOc5OPC/zH328cv5f6ujXj441U0jA7jslMCyCszNvDKjA1+/TNz88krcPPjlgPsOHiMH7ee3Ix1xOc/s35PFn/udRHXta1HVl4BvUd7g09ufiEdGtbiif/+wlUtYrg2MY4l2w5wRbO6OEqxiOIxVyHBDpsWXBQ/lWrk5sknn+Trr79m/fr1vraHH36YNWvWaEKxiASWuxA2zYALe0L2XsyQmhjh0d7NUYPDvatFz38T5r3C+paPsbvFA/Q6+hXMfb7oZ0XEw8UDvQHquGPRbcjL3EehPQR33lHqGUWfMgu0/WYUn7p70MnYzHxPO45Qg1bGDu60/8A/C2/iI3cvjhLGLfYF7DVrsc+sxXYzjgRjH42NDH7wtMeGiR03eQTzgH0Waz2NSac2z9aay7U53/CVuyvDC4Zgw6SpkcZmsz6nbtL63j0di0yyBgiikBDyuePyRN5fuJ17ujTk5f6tAe8WHK5CNxMWbucfc9bTtXFNxt53GfuPuug1egFBNoPHrm7Gg5c30VygKqzS3JbKzs5m61bvEvHt27fn7bffpkePHtSuXZsGDRowatQo0tLSmDRpEnDyUfA//vGPPPjggyxZsoTBgwfrUXARqTg2zoBD270bpKathCY9OL6XBBS6SNu0gpqxCYTXjANHMKZp8t26vbRz7CR+zRjY+A0AGXWSiDvg/X/aTAyMcrx1djqfFvagg20LzW0lT5R+q+BWLrOtI8m+niwzjDvzn2GreQEFOHjJMZFGRgZHCeODwj4sN5szxP4/Hg/6HIBxhdfzeuGdACzv/COO3Ut4YE9/jlCD/WYUC53DMYFerjdp2LARK3cepiZHySKc5AHtuKpFLHuz8thx8BiXN6vLDe/8SNO6Nfj3oE78sHEfrkIPfdsUnZ95qtRDOfzxPytpl1CT5JvbBOTayfmrNOEmJSWFHj16FGkfNGgQH374Iffddx87duwgJSXF9978+fP505/+5FvE78knn9QifiJSdRW6wB7sDUe5h8nIC2Ld7kN0C9uFs8llZOzfx5r/vkHHRnWp+9t/oTAfMncV+1F7wlpQL++3MplcfSbLSWRuQVtGBX16xr5z3e2JNHK41LapxH6L3IlcdnzLkC/d3Xiy4CEiwsM4dCyf3rZl3GGfx2fu7iz0tOGNq2sxZG4ezY1Uruh6Gf9etBMTG23rR9GpQS2uTYzhT5//QtemddiUcZS1ad61ju7q3IDYiBD2Hs3jD90a06RujbP63b+mZVLD6aBRnTM/Yfd7J9Y0ynYV8tnyVAZ0uKBar5JdacKNFRRuRKRKcx2F+X+Fi++CmJZwYCtm+hq21rmaxjGRJ+expLwBv30PsYneeUYZv8A+7y3/5W1fJH/1577gAJBvCyXYU/zk402e+owoeISdZgxfBz9DY9veMv+ZpzO5sCf1jQN0t/9cYr8jZjjPFdzHKvMipgS/zF6zFg/nDyfCyOE3sx5gEEU27wSNobEtg48Lr8aNwR1xe2hy8ZUQfzF54fX5OSOPx2ekEhRagy8Gd6VmaBDfb9xHrbAgnpj6C9v2HwNg+0s9MI7tA2ck5B3x/jO8mInUpgmGwbvztvLOD1v5YnAS4xdsY/rPe7isaTTJN7Xlt982071DK/bneIg5ZdHGvAI38zfv56oWMVVyDpLCTQkUbkRETqPQBZ5C9rsc3PjOj9x4kZMne1wAtRt7n0o7uBWCQskLjWXU2Cl4wuqQVPMwT60++UBH9/rwZtz3pOyP5OJufWkWVxO2zYMfXgXXyZWfP4oezqCDowHY1/U5vnT05a51DxF58OSijjs9MdQysok0cnxtKe52Zwwu52uHJ5ZGZxHQtnrqMcXdg78EfQzAYbMG28x4NnkScBoFZJrhPOCYVeS8/d1eInrntxgxLdjY5nHqLHqRsB1z+Xu9N/nvpgJcBOHGTl2O8G7wGFoZOzhCJDHGYVaFXcZ/M1uwyJPI1JsjqdPqKoZ8tZMZa9P5e1IeNxXMwHRG4oltg715bzi8AyLiIPpC75cfD1FFeNywc7E3JLfo623L3O29xXphT++K5Kc7t4wp3JRA4UZEJHBM02Tc/G2s3HmIp/q0oGlMRPEdC3LBnU/XF75iD9EMSmrEize2hsw07yP7x/9YmjmHMLL2MGPTUSZvMni5fyJ/nbGW1Zu206/mDu66byj1a4Vx518/I7vQzscXziFu21S2eC6gmS2NzbamXOTxzuX80t2NG4NXgDsfO97H4ne2fIiv1u5nmP0rbEbV+vO3zRPHb2Y9rrGvOm2fY6H1CM/dA0BhcBSG6cFmtwEGRt6RoifYg8GdX7QdILop3D7ZuyHvkndgz2po3g9umeBdhyrAFG5KoHAjImKdxb8d4PPlqTx7XSuia5RumY5sVyELNu+nV6tY3221w8fysdkMokKDfKs6O8ln6bP9qJXxI6tXLmVxnVt5pPuFHMopYHP6Idom1CE8JIj1e7KIdhYSu38JBNfg9v9spIZrL4/WXU2C/RC1D60BIN8I5r2Cvtxrn02UkcMbBXfwX/fl7KcWrYwd3Gf/jnjjIBFGLhfbfvPVe9iswST3NQy0f08dI6vI79nqqUdT257zv5gVWY+/QLfhxS/VcI4UbkqgcCMiUvVMW70bt8e77cXZ2nUwh9nrMxjUtRFBdht5ebmEuI+xOdvJw5NX0qpeFM/2a8mlr33vO8fpsPktkhgdFkR2zjEuNPZwyIwgA++tuqSamWw74sZFEFmE48Ebzpoau3nC8RmdbRuY57mYQ2YkWYRx/Q230WjLRyyucwtPzMvhKvtqfvY04VezMQAh5FOTbN4Iep9mtj185e7KNHc3gimkq+1Xrg3dyIzcRI4Rwl+D3gcgx3TyjbsL3e0/s9esSSPDe8stwvDOoSo0bWw34/nY3ZN2tt+4yb7I97uWey7iEtvJNZFOWO9pSCvbztNf1NBaMHRF8fOKzpHCTQkUbkRE5Fzk5rv55pc9dGhYi8bR4Xz9yx7+vXA7797VgQtqhdLnHwvYvDeb7s3r8tO2Qzzc/UIGJTXii5WpBDtsHD5WwBcrU3n1pjZ0aliL0CA7k5bs4IWv1+N02Pj5+V6EBHkXWVyweT/3frDM991XXFSXBZv3+9Xz38FJNIwOp/ub8ziW7+auzg14vFdzvvllD8/+bx2XGBuJMHL4wdOeU9caOsnEgZvCIuv5msRwxLcS9om2RGMH2YSy04wDTJ5xfExNshnnvp7fzAsA6G5bTW/bclp1v4XWV92NzRa4uTkKNyVQuBERkbJwINvFt79mcFun+tgNo1QrLJumyX9X7ia6RjBXtYj1tWfmFtBvzELaJdRkYOcGtK1fkxpOB+v2ZLLzYA7ZrkJu65QAwPIdh1iz6wgDuzQgLNgbVB74cDlLtx0kNjKE/EIPaUe8ozQNaocx9u4ONIoO59CxfN+u9DXDgnAVeHAG2WhatwYrdh4+r2thtxmse/FaX1gLBIWbEijciIhIZWCa5jmvuOzxmOS7Pb5wkZVXwDs/bKVP6zjaNzg5IvPAh8v5YeM+Hr2qKfdf1pjQYDsOm8F9E5f7baER4XQwqGsj3pnnnazdr008M9amA9CrVSyz1/s/XXZtYizv3dPpnGo/HYWbEijciIiIeBW4PazYcZj2DWoWGWXZfTiHn7Ydol/bePLdHmyGwX0fLKNzk9o8fm0L9mV5d6OPiQxh1q/pTF66iz1Hckm+uQ2dmxS/3+P5ULgpgcKNiIhI5XM2f7+r3hKGIiIiUq0p3IiIiEiVonAjIiIiVYrCjYiIiFQpCjciIiJSpSjciIiISJWicCMiIiJVisKNiIiIVCkKNyIiIlKlKNyIiIhIlaJwIyIiIlWKwo2IiIhUKQo3IiIiUqUo3IiIiEiV4rC6gPJmmibg3TpdREREKocTf7dP/B0vSbULN0ePHgUgISHB4kpERETkbB09epSoqKgS+xhmaSJQFeLxeNizZw8REREYhhHQz87KyiIhIYHU1FQiIyMD+tlykq5z+dB1Lj+61uVD17l8lNV1Nk2To0ePUq9ePWy2kmfVVLuRG5vNRv369cv0OyIjI/V/OOVA17l86DqXH13r8qHrXD7K4jqfacTmBE0oFhERkSpF4UZERESqFIWbAHI6nTz//PM4nU6rS6nSdJ3Lh65z+dG1Lh+6zuWjIlznajehWERERKo2jdyIiIhIlaJwIyIiIlWKwo2IiIhUKQo3IiIiUqUo3ATIv/71Lxo3bkxISAgdO3Zk4cKFVpdUqSQnJ3PJJZcQERFBTEwM/fv3Z9OmTX59TNPkhRdeoF69eoSGhtK9e3fWrVvn18flcjFs2DDq1KlDeHg4N9xwA7t37y7Pn1KpJCcnYxgGw4cP97XpOgdGWload999N9HR0YSFhXHxxRezcuVK3/u6zoFRWFjIX/7yFxo3bkxoaChNmjThpZdewuPx+ProWp+9BQsWcP3111OvXj0Mw+Crr77yez9Q1/Tw4cPcc889REVFERUVxT333MORI0fO/weYct6mTJliBgUFme+//765fv1687HHHjPDw8PNnTt3Wl1apXHttdeaEydONH/99VdzzZo1Zr9+/cwGDRqY2dnZvj6vv/66GRERYU6dOtVcu3atefvtt5vx8fFmVlaWr8/gwYPNCy64wJwzZ465atUqs0ePHma7du3MwsJCK35WhbZs2TKzUaNGZtu2bc3HHnvM167rfP4OHTpkNmzY0LzvvvvMn376ydy+fbs5d+5cc+vWrb4+us6B8corr5jR0dHmN998Y27fvt384osvzBo1apijR4/29dG1PnszZ840n3nmGXPq1KkmYE6bNs3v/UBd0969e5utW7c2Fy9ebC5evNhs3bq1ed111513/Qo3AXDppZeagwcP9mtr0aKF+dRTT1lUUeW3b98+EzDnz59vmqZpejweMy4uznz99dd9ffLy8syoqChz3Lhxpmma5pEjR8ygoCBzypQpvj5paWmmzWYzZ82aVb4/oII7evSo2axZM3POnDnmlVde6Qs3us6B8eSTT5rdunU77fu6zoHTr18/84EHHvBru/nmm827777bNE1d60D4fbgJ1DVdv369CZhLly719VmyZIkJmBs3bjyvmnVb6jzl5+ezcuVKevXq5dfeq1cvFi9ebFFVlV9mZiYAtWvXBmD79u1kZGT4XWen08mVV17pu84rV66koKDAr0+9evVo3bq1/rP4nSFDhtCvXz+uvvpqv3Zd58CYPn06nTp14tZbbyUmJob27dvz/vvv+97XdQ6cbt268f3337N582YAfv75Z3788Uf69u0L6FqXhUBd0yVLlhAVFUXnzp19fbp06UJUVNR5X/dqt3FmoB04cAC3201sbKxfe2xsLBkZGRZVVbmZpsmIESPo1q0brVu3BvBdy+Ku886dO319goODqVWrVpE++s/ipClTprBq1SqWL19e5D1d58DYtm0bY8eOZcSIETz99NMsW7aMRx99FKfTyb333qvrHEBPPvkkmZmZtGjRArvdjtvt5tVXX+XOO+8E9N/pshCoa5qRkUFMTEyRz4+JiTnv665wEyCGYfgdm6ZZpE1KZ+jQofzyyy/8+OOPRd47l+us/yxOSk1N5bHHHmP27NmEhISctp+u8/nxeDx06tSJ1157DYD27duzbt06xo4dy7333uvrp+t8/j777DMmT57MJ598QmJiImvWrGH48OHUq1ePQYMG+frpWgdeIK5pcf0Dcd11W+o81alTB7vdXiRl7tu3r0iqlTMbNmwY06dPZ968edSvX9/XHhcXB1DidY6LiyM/P5/Dhw+ftk91t3LlSvbt20fHjh1xOBw4HA7mz5/PmDFjcDgcvuuk63x+4uPjadWqlV9by5Yt2bVrF6D/PgfS448/zlNPPcUdd9xBmzZtuOeee/jTn/5EcnIyoGtdFgJ1TePi4ti7d2+Rz9+/f/95X3eFm/MUHBxMx44dmTNnjl/7nDlz6Nq1q0VVVT6maTJ06FC+/PJLfvjhBxo3buz3fuPGjYmLi/O7zvn5+cyfP993nTt27EhQUJBfn/T0dH799Vf9Z3Fcz549Wbt2LWvWrPG9OnXqxMCBA1mzZg1NmjTRdQ6Ayy67rMhSBps3b6Zhw4aA/vscSDk5Odhs/n/K7Ha771FwXevAC9Q1TUpKIjMzk2XLlvn6/PTTT2RmZp7/dT+v6chimubJR8EnTJhgrl+/3hw+fLgZHh5u7tixw+rSKo2HH37YjIqKMlNSUsz09HTfKycnx9fn9ddfN6Oioswvv/zSXLt2rXnnnXcW++hh/fr1zblz55qrVq0yr7rqqmr9OGdpnPq0lGnqOgfCsmXLTIfDYb766qvmli1bzI8//tgMCwszJ0+e7Ouj6xwYgwYNMi+44ALfo+BffvmlWadOHfOJJ57w9dG1PntHjx41V69eba5evdoEzLfffttcvXq1b4mTQF3T3r17m23btjWXLFliLlmyxGzTpo0eBa9I3n33XbNhw4ZmcHCw2aFDB98jzFI6QLGviRMn+vp4PB7z+eefN+Pi4kyn02leccUV5tq1a/0+Jzc31xw6dKhZu3ZtMzQ01LzuuuvMXbt2lfOvqVx+H250nQPj66+/Nlu3bm06nU6zRYsW5vjx4/3e13UOjKysLPOxxx4zGzRoYIaEhJhNmjQxn3nmGdPlcvn66FqfvXnz5hX7v8mDBg0yTTNw1/TgwYPmwIEDzYiICDMiIsIcOHCgefjw4fOu3zBN0zy/sR8RERGRikNzbkRERKRKUbgRERGRKkXhRkRERKoUhRsRERGpUhRuREREpEpRuBEREZEqReFGREREqhSFGxGplgzD4KuvvrK6DBEpAwo3IlLu7rvvPgzDKPLq3bu31aWJSBXgsLoAEameevfuzcSJE/3anE6nRdWISFWikRsRsYTT6SQuLs7vVatWLcB7y2js2LH06dOH0NBQGjduzBdffOF3/tq1a7nqqqsIDQ0lOjqahx56iOzsbL8+H3zwAYmJiTidTuLj4xk6dKjf+wcOHOCmm24iLCyMZs2aMX36dN97hw8fZuDAgdStW5fQ0FCaNWtWJIyJSMWkcCMiFdKzzz7LgAED+Pnnn7n77ru588472bBhAwA5OTn07t2bWrVqsXz5cr744gvmzp3rF17Gjh3LkCFDeOihh1i7di3Tp0+nadOmft/x4osvctttt/HLL7/Qt29fBg4cyKFDh3zfv379er799ls2bNjA2LFjqVOnTvldABE5d+e99aaIyFkaNGiQabfbzfDwcL/XSy+9ZJqmd5f4wYMH+53TuXNn8+GHHzZN0zTHjx9v1qpVy8zOzva9P2PGDNNms5kZGRmmaZpmvXr1zGeeeea0NQDmX/7yF99xdna2aRiG+e2335qmaZrXX3+9ef/99wfmB4tIudKcGxGxRI8ePRg7dqxfW+3atX3/npSU5PdeUlISa9asAWDDhg20a9eO8PBw3/uXXXYZHo+HTZs2YRgGe/bsoWfPniXW0LZtW9+/h4eHExERwb59+wB4+OGHGTBgAKtWraJXr17079+frl27ntNvFZHypXAjIpYIDw8vcpvoTAzDAMA0Td+/F9cnNDS0VJ8XFBRU5FyPxwNAnz592LlzJzNmzGDu3Ln07NmTIUOG8NZbb51VzSJS/jTnRkQqpKVLlxY5btGiBQCtWrVizZo1HDt2zPf+okWLsNlsXHTRRURERNCoUSO+//7786qhbt263HfffUyePJnRo0czfvz48/o8ESkfGrkREUu4XC4yMjL82hwOh2/S7hdffEGnTp3o1q0bH3/8McuWLWPChAkADBw4kOeff55BgwbxwgsvsH//foYNG8Y999xDbGwsAC+88AKDBw8mJiaGPn36cPToURYtWsSwYcNKVd9zzz1Hx44dSUxMxOVy8c0339CyZcsAXgERKSsKNyJiiVmzZhEfH+/X1rx5czZu3Ah4n2SaMmUKjzzyCHFxcXz88ce0atUKgLCwML777jsee+wxLrnkEsLCwhgwYABvv/2277MGDRpEXl4ef//73xk5ciR16tThlltuKXV9wcHBjBo1ih07dhAaGsrll1/OlClTAvDLRaSsGaZpmlYXISJyKsMwmDZtGv3797e6FBGphDTnRkRERKoUhRsRERGpUjTnRkQqHN0tF5HzoZEbERERqVIUbkRERKRKUbgRERGRKkXhRkRERKoUhRsRERGpUhRuREREpEpRuBEREZEqReFGREREqhSFGxEREalS/h/CWTPV2nd7ZgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#run\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.savefig(\"audio_dm_3_featu_.jpg\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
